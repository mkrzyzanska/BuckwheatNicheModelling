{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Making simple model with stan\n",
    "setwd(\"G:\\\\My Drive\\\\stan_practice\\\\seaice.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Date</th><th scope=col>Value</th><th scope=col>Anomaly</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1979</td><td>8.04</td><td>0.84</td></tr>\n",
       "\t<tr><td>1980</td><td>7.98</td><td>0.78</td></tr>\n",
       "\t<tr><td>1981</td><td>7.84</td><td>0.64</td></tr>\n",
       "\t<tr><td>1982</td><td>8.14</td><td>0.94</td></tr>\n",
       "\t<tr><td>1983</td><td>8.19</td><td>0.99</td></tr>\n",
       "\t<tr><td>1984</td><td>7.77</td><td>0.57</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " Date & Value & Anomaly\\\\\n",
       "\\hline\n",
       "\t 1979 & 8.04 & 0.84\\\\\n",
       "\t 1980 & 7.98 & 0.78\\\\\n",
       "\t 1981 & 7.84 & 0.64\\\\\n",
       "\t 1982 & 8.14 & 0.94\\\\\n",
       "\t 1983 & 8.19 & 0.99\\\\\n",
       "\t 1984 & 7.77 & 0.57\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "Date | Value | Anomaly | \n",
       "|---|---|---|---|---|---|\n",
       "| 1979 | 8.04 | 0.84 | \n",
       "| 1980 | 7.98 | 0.78 | \n",
       "| 1981 | 7.84 | 0.64 | \n",
       "| 1982 | 8.14 | 0.94 | \n",
       "| 1983 | 8.19 | 0.99 | \n",
       "| 1984 | 7.77 | 0.57 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  Date Value Anomaly\n",
       "1 1979 8.04  0.84   \n",
       "2 1980 7.98  0.78   \n",
       "3 1981 7.84  0.64   \n",
       "4 1982 8.14  0.94   \n",
       "5 1983 8.19  0.99   \n",
       "6 1984 7.77  0.57   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seaice <- read.csv(\"seaice2.csv\", stringsAsFactors = F)\n",
    "head(seaice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nAO5kFtV5VG+NAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(Value ~ Date, pch = 20, data = seaice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = Value ~ Date, data = seaice)\n",
       "\n",
       "Residuals:\n",
       "     Min       1Q   Median       3Q      Max \n",
       "-1.15024 -0.26501 -0.00928  0.27689  1.09069 \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept) 159.167815  11.664534   13.64  < 2e-16 ***\n",
       "Date         -0.076192   0.005835  -13.06  8.1e-16 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 0.4421 on 39 degrees of freedom\n",
       "Multiple R-squared:  0.8138,\tAdjusted R-squared:  0.8091 \n",
       "F-statistic: 170.5 on 1 and 39 DF,  p-value: 8.104e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm1 <- lm(Value ~ Date, data = seaice)\n",
    "summary(lm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAM1BMVEUAAABNTU1oaGh8fHyM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\nGbtWlUNoNwAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(Value ~ Date, pch = 20, data = seaice)\n",
    "abline(lm1, col = 2, lty = 2, lw = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x <- I(seaice$Date - 1978) # Independent variable - will be an equivalent of temperature, etc.\n",
    "y <- seaice$Value # Dependent variable  - equivalent of buckwheat production\n",
    "N <- length(seaice$Date) # Number of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = y ~ x)\n",
       "\n",
       "Residuals:\n",
       "     Min       1Q   Median       3Q      Max \n",
       "-1.15024 -0.26501 -0.00928  0.27689  1.09069 \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  8.460756   0.140648   60.16  < 2e-16 ***\n",
       "x           -0.076192   0.005835  -13.06  8.1e-16 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 0.4421 on 39 degrees of freedom\n",
       "Multiple R-squared:  0.8138,\tAdjusted R-squared:  0.8091 \n",
       "F-statistic: 170.5 on 1 and 39 DF,  p-value: 8.104e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm1 <- lm(y ~ x)\n",
    "summary(lm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "8.46075609756097"
      ],
      "text/latex": [
       "8.46075609756097"
      ],
      "text/markdown": [
       "8.46075609756097"
      ],
      "text/plain": [
       "[1] 8.460756"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "-0.076191637630662"
      ],
      "text/latex": [
       "-0.076191637630662"
      ],
      "text/markdown": [
       "-0.076191637630662"
      ],
      "text/plain": [
       "[1] -0.07619164"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.442082114642563"
      ],
      "text/latex": [
       "0.442082114642563"
      ],
      "text/markdown": [
       "0.442082114642563"
      ],
      "text/plain": [
       "[1] 0.4420821"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(lm_alpha <- summary(lm1)$coeff[1])  # the intercept\n",
    "(lm_beta <- summary(lm1)$coeff[2])  # the slope\n",
    "(lm_sigma <- sigma(lm1))  # the residual error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stan_data <- list(N = N, x = x, y = y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'rstan' was built under R version 3.4.4\"Loading required package: ggplot2\n",
      "Warning message:\n",
      "\"package 'ggplot2' was built under R version 3.4.4\"Loading required package: StanHeaders\n",
      "Warning message:\n",
      "\"package 'StanHeaders' was built under R version 3.4.4\"rstan (Version 2.18.2, GitRev: 2e1f913d3ca3)\n",
      "For execution on a local, multicore CPU with excess RAM we recommend calling\n",
      "options(mc.cores = parallel::detectCores()).\n",
      "To avoid recompilation of unchanged Stan programs, we recommend calling\n",
      "rstan_options(auto_write = TRUE)\n",
      "For improved execution time, we recommend calling\n",
      "Sys.setenv(LOCAL_CPPFLAGS = '-march=native')\n",
      "although this causes Stan to throw an error on a few processors.\n",
      "Warning message:\n",
      "\"package 'gdata' was built under R version 3.4.4\"gdata: Unable to locate valid perl interpreter\n",
      "gdata: \n",
      "gdata: read.xls() will be unable to read Excel XLS and XLSX files\n",
      "gdata: unless the 'perl=' argument is used to specify the location of a\n",
      "gdata: valid perl intrpreter.\n",
      "gdata: \n",
      "gdata: (To avoid display of this message in the future, please ensure\n",
      "gdata: perl is installed and available on the executable search path.)\n",
      "gdata: Unable to load perl libaries needed by read.xls()\n",
      "gdata: to support 'XLX' (Excel 97-2004) files.\n",
      "\n",
      "gdata: Unable to load perl libaries needed by read.xls()\n",
      "gdata: to support 'XLSX' (Excel 2007+) files.\n",
      "\n",
      "gdata: Run the function 'installXLSXsupport()'\n",
      "gdata: to automatically download and install the perl\n",
      "gdata: libaries needed to support Excel XLS and XLSX formats.\n",
      "\n",
      "Attaching package: 'gdata'\n",
      "\n",
      "The following object is masked from 'package:stats':\n",
      "\n",
      "    nobs\n",
      "\n",
      "The following object is masked from 'package:utils':\n",
      "\n",
      "    object.size\n",
      "\n",
      "The following object is masked from 'package:base':\n",
      "\n",
      "    startsWith\n",
      "\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in library(bayesplot): there is no package called 'bayesplot'\n",
     "output_type": "error",
     "traceback": [
      "Error in library(bayesplot): there is no package called 'bayesplot'\nTraceback:\n",
      "1. library(bayesplot)",
      "2. stop(txt, domain = NA)"
     ]
    }
   ],
   "source": [
    "library(rstan)\n",
    "library(gdata)\n",
    "library(bayesplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write(\"// Stan model for simple linear regression\n",
    "\n",
    "data {\n",
    " int < lower = 1 > N; // Sample size is an integer with the lowest value of 1 (i.e. positive)\n",
    " vector[N] x; // Predictor is a vector of the size of sample size\n",
    " vector[N] y; // Outcome is a vector of a size of sample size\n",
    "}\n",
    "\n",
    "parameters {\n",
    " real alpha; // Intercept is an unconstrained continous value\n",
    " real beta; // Slope (regression coefficients) is an unconstrained continous value\n",
    " real < lower = 0 > sigma; // Error SD is an unconstrained positive continous valeu\n",
    "}\n",
    "\n",
    "model {\n",
    " y ~ normal(alpha + x * beta , sigma); //this seem to declare the model\n",
    "}\n",
    "generated quantities {\n",
    "} // The posterior predictive distribution\",\n",
    "\n",
    "\"stan_model1.stan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$status</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>$model_cppname</dt>\n",
       "\t\t<dd>'model4fa476daf76_stan_model1'</dd>\n",
       "\t<dt>$cppcode</dt>\n",
       "\t\t<dd><span style=white-space:pre-wrap>'// Code generated by Stan version 2.18.1\\n\\n#include &lt;stan/model/model_header.hpp&gt;\\n\\nnamespace model4fa476daf76_stan_model1_namespace {\\n\\nusing std::istream;\\nusing std::string;\\nusing std::stringstream;\\nusing std::vector;\\nusing stan::io::dump;\\nusing stan::math::lgamma;\\nusing stan::model::prob_grad;\\nusing namespace stan::math;\\n\\nstatic int current_statement_begin__;\\n\\nstan::io::program_reader prog_reader__() {\\n    stan::io::program_reader reader;\\n    reader.add_event(0, 0, \"start\", \"model4fa476daf76_stan_model1\");\\n    reader.add_event(21, 19, \"end\", \"model4fa476daf76_stan_model1\");\\n    return reader;\\n}\\n\\nclass model4fa476daf76_stan_model1 : public prob_grad {\\nprivate:\\n    int N;\\n    vector_d x;\\n    vector_d y;\\npublic:\\n    model4fa476daf76_stan_model1(stan::io::var_context&amp; context__,\\n        std::ostream* pstream__ = 0)\\n        : prob_grad(0) {\\n        ctor_body(context__, 0, pstream__);\\n    }\\n\\n    model4fa476daf76_stan_model1(stan::io::var_context&amp; context__,\\n        unsigned int random_seed__,\\n        std::ostream* pstream__ = 0)\\n        : prob_grad(0) {\\n        ctor_body(context__, random_seed__, pstream__);\\n    }\\n\\n    void ctor_body(stan::io::var_context&amp; context__,\\n                   unsigned int random_seed__,\\n                   std::ostream* pstream__) {\\n        typedef double local_scalar_t__;\\n\\n        boost::ecuyer1988 base_rng__ =\\n          stan::services::util::create_rng(random_seed__, 0);\\n        (void) base_rng__;  // suppress unused var warning\\n\\n        current_statement_begin__ = -1;\\n\\n        static const char* function__ = \"model4fa476daf76_stan_model1_namespace::model4fa476daf76_stan_model1\";\\n        (void) function__;  // dummy to suppress unused var warning\\n        size_t pos__;\\n        (void) pos__;  // dummy to suppress unused var warning\\n        std::vector&lt;int&gt; vals_i__;\\n        std::vector&lt;double&gt; vals_r__;\\n        local_scalar_t__ DUMMY_VAR__(std::numeric_limits&lt;double&gt;::quiet_NaN());\\n        (void) DUMMY_VAR__;  // suppress unused var warning\\n\\n        // initialize member variables\\n        try {\\n            current_statement_begin__ = 4;\\n            context__.validate_dims(\"data initialization\", \"N\", \"int\", context__.to_vec());\\n            N = int(0);\\n            vals_i__ = context__.vals_i(\"N\");\\n            pos__ = 0;\\n            N = vals_i__[pos__++];\\n            current_statement_begin__ = 5;\\n            validate_non_negative_index(\"x\", \"N\", N);\\n            context__.validate_dims(\"data initialization\", \"x\", \"vector_d\", context__.to_vec(N));\\n            validate_non_negative_index(\"x\", \"N\", N);\\n            x = vector_d(static_cast&lt;Eigen::VectorXd::Index&gt;(N));\\n            vals_r__ = context__.vals_r(\"x\");\\n            pos__ = 0;\\n            size_t x_i_vec_lim__ = N;\\n            for (size_t i_vec__ = 0; i_vec__ &lt; x_i_vec_lim__; ++i_vec__) {\\n                x[i_vec__] = vals_r__[pos__++];\\n            }\\n            current_statement_begin__ = 6;\\n            validate_non_negative_index(\"y\", \"N\", N);\\n            context__.validate_dims(\"data initialization\", \"y\", \"vector_d\", context__.to_vec(N));\\n            validate_non_negative_index(\"y\", \"N\", N);\\n            y = vector_d(static_cast&lt;Eigen::VectorXd::Index&gt;(N));\\n            vals_r__ = context__.vals_r(\"y\");\\n            pos__ = 0;\\n            size_t y_i_vec_lim__ = N;\\n            for (size_t i_vec__ = 0; i_vec__ &lt; y_i_vec_lim__; ++i_vec__) {\\n                y[i_vec__] = vals_r__[pos__++];\\n            }\\n\\n            // validate, data variables\\n            current_statement_begin__ = 4;\\n            check_greater_or_equal(function__,\"N\",N,1);\\n            current_statement_begin__ = 5;\\n            current_statement_begin__ = 6;\\n            // initialize data variables\\n\\n\\n            // validate transformed data\\n\\n            // validate, set parameter ranges\\n            num_params_r__ = 0U;\\n            param_ranges_i__.clear();\\n            current_statement_begin__ = 10;\\n            ++num_params_r__;\\n            current_statement_begin__ = 11;\\n            ++num_params_r__;\\n            current_statement_begin__ = 12;\\n            ++num_params_r__;\\n        } catch (const std::exception&amp; e) {\\n            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());\\n            // Next line prevents compiler griping about no return\\n            throw std::runtime_error(\"*** IF YOU SEE THIS, PLEASE REPORT A BUG ***\");\\n        }\\n    }\\n\\n    ~model4fa476daf76_stan_model1() { }\\n\\n\\n    void transform_inits(const stan::io::var_context&amp; context__,\\n                         std::vector&lt;int&gt;&amp; params_i__,\\n                         std::vector&lt;double&gt;&amp; params_r__,\\n                         std::ostream* pstream__) const {\\n        stan::io::writer&lt;double&gt; writer__(params_r__,params_i__);\\n        size_t pos__;\\n        (void) pos__; // dummy call to supress warning\\n        std::vector&lt;double&gt; vals_r__;\\n        std::vector&lt;int&gt; vals_i__;\\n\\n        if (!(context__.contains_r(\"alpha\")))\\n            throw std::runtime_error(\"variable alpha missing\");\\n        vals_r__ = context__.vals_r(\"alpha\");\\n        pos__ = 0U;\\n        context__.validate_dims(\"initialization\", \"alpha\", \"double\", context__.to_vec());\\n        double alpha(0);\\n        alpha = vals_r__[pos__++];\\n        try {\\n            writer__.scalar_unconstrain(alpha);\\n        } catch (const std::exception&amp; e) { \\n            throw std::runtime_error(std::string(\"Error transforming variable alpha: \") + e.what());\\n        }\\n\\n        if (!(context__.contains_r(\"beta\")))\\n            throw std::runtime_error(\"variable beta missing\");\\n        vals_r__ = context__.vals_r(\"beta\");\\n        pos__ = 0U;\\n        context__.validate_dims(\"initialization\", \"beta\", \"double\", context__.to_vec());\\n        double beta(0);\\n        beta = vals_r__[pos__++];\\n        try {\\n            writer__.scalar_unconstrain(beta);\\n        } catch (const std::exception&amp; e) { \\n            throw std::runtime_error(std::string(\"Error transforming variable beta: \") + e.what());\\n        }\\n\\n        if (!(context__.contains_r(\"sigma\")))\\n            throw std::runtime_error(\"variable sigma missing\");\\n        vals_r__ = context__.vals_r(\"sigma\");\\n        pos__ = 0U;\\n        context__.validate_dims(\"initialization\", \"sigma\", \"double\", context__.to_vec());\\n        double sigma(0);\\n        sigma = vals_r__[pos__++];\\n        try {\\n            writer__.scalar_lb_unconstrain(0,sigma);\\n        } catch (const std::exception&amp; e) { \\n            throw std::runtime_error(std::string(\"Error transforming variable sigma: \") + e.what());\\n        }\\n\\n        params_r__ = writer__.data_r();\\n        params_i__ = writer__.data_i();\\n    }\\n\\n    void transform_inits(const stan::io::var_context&amp; context,\\n                         Eigen::Matrix&lt;double,Eigen::Dynamic,1&gt;&amp; params_r,\\n                         std::ostream* pstream__) const {\\n      std::vector&lt;double&gt; params_r_vec;\\n      std::vector&lt;int&gt; params_i_vec;\\n      transform_inits(context, params_i_vec, params_r_vec, pstream__);\\n      params_r.resize(params_r_vec.size());\\n      for (int i = 0; i &lt; params_r.size(); ++i)\\n        params_r(i) = params_r_vec[i];\\n    }\\n\\n\\n    template &lt;bool propto__, bool jacobian__, typename T__&gt;\\n    T__ log_prob(vector&lt;T__&gt;&amp; params_r__,\\n                 vector&lt;int&gt;&amp; params_i__,\\n                 std::ostream* pstream__ = 0) const {\\n\\n        typedef T__ local_scalar_t__;\\n\\n        local_scalar_t__ DUMMY_VAR__(std::numeric_limits&lt;double&gt;::quiet_NaN());\\n        (void) DUMMY_VAR__;  // suppress unused var warning\\n\\n        T__ lp__(0.0);\\n        stan::math::accumulator&lt;T__&gt; lp_accum__;\\n\\n        try {\\n            // model parameters\\n            stan::io::reader&lt;local_scalar_t__&gt; in__(params_r__,params_i__);\\n\\n            local_scalar_t__ alpha;\\n            (void) alpha;  // dummy to suppress unused var warning\\n            if (jacobian__)\\n                alpha = in__.scalar_constrain(lp__);\\n            else\\n                alpha = in__.scalar_constrain();\\n\\n            local_scalar_t__ beta;\\n            (void) beta;  // dummy to suppress unused var warning\\n            if (jacobian__)\\n                beta = in__.scalar_constrain(lp__);\\n            else\\n                beta = in__.scalar_constrain();\\n\\n            local_scalar_t__ sigma;\\n            (void) sigma;  // dummy to suppress unused var warning\\n            if (jacobian__)\\n                sigma = in__.scalar_lb_constrain(0,lp__);\\n            else\\n                sigma = in__.scalar_lb_constrain(0);\\n\\n\\n            // transformed parameters\\n\\n\\n\\n            // validate transformed parameters\\n\\n            const char* function__ = \"validate transformed params\";\\n            (void) function__;  // dummy to suppress unused var warning\\n\\n            // model body\\n\\n            current_statement_begin__ = 16;\\n            lp_accum__.add(normal_log&lt;propto__&gt;(y, add(alpha,multiply(x,beta)), sigma));\\n\\n        } catch (const std::exception&amp; e) {\\n            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());\\n            // Next line prevents compiler griping about no return\\n            throw std::runtime_error(\"*** IF YOU SEE THIS, PLEASE REPORT A BUG ***\");\\n        }\\n\\n        lp_accum__.add(lp__);\\n        return lp_accum__.sum();\\n\\n    } // log_prob()\\n\\n    template &lt;bool propto, bool jacobian, typename T_&gt;\\n    T_ log_prob(Eigen::Matrix&lt;T_,Eigen::Dynamic,1&gt;&amp; params_r,\\n               std::ostream* pstream = 0) const {\\n      std::vector&lt;T_&gt; vec_params_r;\\n      vec_params_r.reserve(params_r.size());\\n      for (int i = 0; i &lt; params_r.size(); ++i)\\n        vec_params_r.push_back(params_r(i));\\n      std::vector&lt;int&gt; vec_params_i;\\n      return log_prob&lt;propto,jacobian,T_&gt;(vec_params_r, vec_params_i, pstream);\\n    }\\n\\n\\n    void get_param_names(std::vector&lt;std::string&gt;&amp; names__) const {\\n        names__.resize(0);\\n        names__.push_back(\"alpha\");\\n        names__.push_back(\"beta\");\\n        names__.push_back(\"sigma\");\\n    }\\n\\n\\n    void get_dims(std::vector&lt;std::vector&lt;size_t&gt; &gt;&amp; dimss__) const {\\n        dimss__.resize(0);\\n        std::vector&lt;size_t&gt; dims__;\\n        dims__.resize(0);\\n        dimss__.push_back(dims__);\\n        dims__.resize(0);\\n        dimss__.push_back(dims__);\\n        dims__.resize(0);\\n        dimss__.push_back(dims__);\\n    }\\n\\n    template &lt;typename RNG&gt;\\n    void write_array(RNG&amp; base_rng__,\\n                     std::vector&lt;double&gt;&amp; params_r__,\\n                     std::vector&lt;int&gt;&amp; params_i__,\\n                     std::vector&lt;double&gt;&amp; vars__,\\n                     bool include_tparams__ = true,\\n                     bool include_gqs__ = true,\\n                     std::ostream* pstream__ = 0) const {\\n        typedef double local_scalar_t__;\\n\\n        vars__.resize(0);\\n        stan::io::reader&lt;local_scalar_t__&gt; in__(params_r__,params_i__);\\n        static const char* function__ = \"model4fa476daf76_stan_model1_namespace::write_array\";\\n        (void) function__;  // dummy to suppress unused var warning\\n        // read-transform, write parameters\\n        double alpha = in__.scalar_constrain();\\n        double beta = in__.scalar_constrain();\\n        double sigma = in__.scalar_lb_constrain(0);\\n        vars__.push_back(alpha);\\n        vars__.push_back(beta);\\n        vars__.push_back(sigma);\\n\\n        // declare and define transformed parameters\\n        double lp__ = 0.0;\\n        (void) lp__;  // dummy to suppress unused var warning\\n        stan::math::accumulator&lt;double&gt; lp_accum__;\\n\\n        local_scalar_t__ DUMMY_VAR__(std::numeric_limits&lt;double&gt;::quiet_NaN());\\n        (void) DUMMY_VAR__;  // suppress unused var warning\\n\\n        try {\\n\\n\\n\\n            // validate transformed parameters\\n\\n            // write transformed parameters\\n            if (include_tparams__) {\\n            }\\n            if (!include_gqs__) return;\\n            // declare and define generated quantities\\n\\n\\n\\n            // validate generated quantities\\n\\n            // write generated quantities\\n        } catch (const std::exception&amp; e) {\\n            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());\\n            // Next line prevents compiler griping about no return\\n            throw std::runtime_error(\"*** IF YOU SEE THIS, PLEASE REPORT A BUG ***\");\\n        }\\n    }\\n\\n    template &lt;typename RNG&gt;\\n    void write_array(RNG&amp; base_rng,\\n                     Eigen::Matrix&lt;double,Eigen::Dynamic,1&gt;&amp; params_r,\\n                     Eigen::Matrix&lt;double,Eigen::Dynamic,1&gt;&amp; vars,\\n                     bool include_tparams = true,\\n                     bool include_gqs = true,\\n                     std::ostream* pstream = 0) const {\\n      std::vector&lt;double&gt; params_r_vec(params_r.size());\\n      for (int i = 0; i &lt; params_r.size(); ++i)\\n        params_r_vec[i] = params_r(i);\\n      std::vector&lt;double&gt; vars_vec;\\n      std::vector&lt;int&gt; params_i_vec;\\n      write_array(base_rng,params_r_vec,params_i_vec,vars_vec,include_tparams,include_gqs,pstream);\\n      vars.resize(vars_vec.size());\\n      for (int i = 0; i &lt; vars.size(); ++i)\\n        vars(i) = vars_vec[i];\\n    }\\n\\n    static std::string model_name() {\\n        return \"model4fa476daf76_stan_model1\";\\n    }\\n\\n\\n    void constrained_param_names(std::vector&lt;std::string&gt;&amp; param_names__,\\n                                 bool include_tparams__ = true,\\n                                 bool include_gqs__ = true) const {\\n        std::stringstream param_name_stream__;\\n        param_name_stream__.str(std::string());\\n        param_name_stream__ &lt;&lt; \"alpha\";\\n        param_names__.push_back(param_name_stream__.str());\\n        param_name_stream__.str(std::string());\\n        param_name_stream__ &lt;&lt; \"beta\";\\n        param_names__.push_back(param_name_stream__.str());\\n        param_name_stream__.str(std::string());\\n        param_name_stream__ &lt;&lt; \"sigma\";\\n        param_names__.push_back(param_name_stream__.str());\\n\\n        if (!include_gqs__ &amp;&amp; !include_tparams__) return;\\n\\n        if (include_tparams__) {\\n        }\\n\\n\\n        if (!include_gqs__) return;\\n    }\\n\\n\\n    void unconstrained_param_names(std::vector&lt;std::string&gt;&amp; param_names__,\\n                                   bool include_tparams__ = true,\\n                                   bool include_gqs__ = true) const {\\n        std::stringstream param_name_stream__;\\n        param_name_stream__.str(std::string());\\n        param_name_stream__ &lt;&lt; \"alpha\";\\n        param_names__.push_back(param_name_stream__.str());\\n        param_name_stream__.str(std::string());\\n        param_name_stream__ &lt;&lt; \"beta\";\\n        param_names__.push_back(param_name_stream__.str());\\n        param_name_stream__.str(std::string());\\n        param_name_stream__ &lt;&lt; \"sigma\";\\n        param_names__.push_back(param_name_stream__.str());\\n\\n        if (!include_gqs__ &amp;&amp; !include_tparams__) return;\\n\\n        if (include_tparams__) {\\n        }\\n\\n\\n        if (!include_gqs__) return;\\n    }\\n\\n}; // model\\n\\n}\\n\\ntypedef model4fa476daf76_stan_model1_namespace::model4fa476daf76_stan_model1 stan_model;\\n\\n'</span></dd>\n",
       "\t<dt>$model_name</dt>\n",
       "\t\t<dd>'stan_model1'</dd>\n",
       "\t<dt>$model_code</dt>\n",
       "\t\t<dd>'// Stan model for simple linear regression\\n\\ndata {\\n int &lt; lower = 1 &gt; N; // Sample size is an integer with the lowest value of 1 (i.e. positive)\\n vector[N] x; // Predictor is a vector of the size of sample size\\n vector[N] y; // Outcome is a vector of a size of sample size\\n}\\n\\nparameters {\\n real alpha; // Intercept is an unconstrained continous value\\n real beta; // Slope (regression coefficients) is an unconstrained continous value\\n real &lt; lower = 0 &gt; sigma; // Error SD is an unconstrained positive continous valeu\\n}\\n\\nmodel {\\n y ~ normal(alpha + x * beta , sigma); //this seem to declare the model\\n}\\ngenerated quantities {\\n} // The posterior predictive distribution'</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$status] TRUE\n",
       "\\item[\\$model\\_cppname] 'model4fa476daf76\\_stan\\_model1'\n",
       "\\item[\\$cppcode] '// Code generated by Stan version 2.18.1\\textbackslash{}n\\textbackslash{}n\\#include <stan/model/model\\_header.hpp>\\textbackslash{}n\\textbackslash{}nnamespace model4fa476daf76\\_stan\\_model1\\_namespace \\{\\textbackslash{}n\\textbackslash{}nusing std::istream;\\textbackslash{}nusing std::string;\\textbackslash{}nusing std::stringstream;\\textbackslash{}nusing std::vector;\\textbackslash{}nusing stan::io::dump;\\textbackslash{}nusing stan::math::lgamma;\\textbackslash{}nusing stan::model::prob\\_grad;\\textbackslash{}nusing namespace stan::math;\\textbackslash{}n\\textbackslash{}nstatic int current\\_statement\\_begin\\_\\_;\\textbackslash{}n\\textbackslash{}nstan::io::program\\_reader prog\\_reader\\_\\_() \\{\\textbackslash{}n    stan::io::program\\_reader reader;\\textbackslash{}n    reader.add\\_event(0, 0, \"start\", \"model4fa476daf76\\_stan\\_model1\");\\textbackslash{}n    reader.add\\_event(21, 19, \"end\", \"model4fa476daf76\\_stan\\_model1\");\\textbackslash{}n    return reader;\\textbackslash{}n\\}\\textbackslash{}n\\textbackslash{}nclass model4fa476daf76\\_stan\\_model1 : public prob\\_grad \\{\\textbackslash{}nprivate:\\textbackslash{}n    int N;\\textbackslash{}n    vector\\_d x;\\textbackslash{}n    vector\\_d y;\\textbackslash{}npublic:\\textbackslash{}n    model4fa476daf76\\_stan\\_model1(stan::io::var\\_context\\& context\\_\\_,\\textbackslash{}n        std::ostream* pstream\\_\\_ = 0)\\textbackslash{}n        : prob\\_grad(0) \\{\\textbackslash{}n        ctor\\_body(context\\_\\_, 0, pstream\\_\\_);\\textbackslash{}n    \\}\\textbackslash{}n\\textbackslash{}n    model4fa476daf76\\_stan\\_model1(stan::io::var\\_context\\& context\\_\\_,\\textbackslash{}n        unsigned int random\\_seed\\_\\_,\\textbackslash{}n        std::ostream* pstream\\_\\_ = 0)\\textbackslash{}n        : prob\\_grad(0) \\{\\textbackslash{}n        ctor\\_body(context\\_\\_, random\\_seed\\_\\_, pstream\\_\\_);\\textbackslash{}n    \\}\\textbackslash{}n\\textbackslash{}n    void ctor\\_body(stan::io::var\\_context\\& context\\_\\_,\\textbackslash{}n                   unsigned int random\\_seed\\_\\_,\\textbackslash{}n                   std::ostream* pstream\\_\\_) \\{\\textbackslash{}n        typedef double local\\_scalar\\_t\\_\\_;\\textbackslash{}n\\textbackslash{}n        boost::ecuyer1988 base\\_rng\\_\\_ =\\textbackslash{}n          stan::services::util::create\\_rng(random\\_seed\\_\\_, 0);\\textbackslash{}n        (void) base\\_rng\\_\\_;  // suppress unused var warning\\textbackslash{}n\\textbackslash{}n        current\\_statement\\_begin\\_\\_ = -1;\\textbackslash{}n\\textbackslash{}n        static const char* function\\_\\_ = \"model4fa476daf76\\_stan\\_model1\\_namespace::model4fa476daf76\\_stan\\_model1\";\\textbackslash{}n        (void) function\\_\\_;  // dummy to suppress unused var warning\\textbackslash{}n        size\\_t pos\\_\\_;\\textbackslash{}n        (void) pos\\_\\_;  // dummy to suppress unused var warning\\textbackslash{}n        std::vector<int> vals\\_i\\_\\_;\\textbackslash{}n        std::vector<double> vals\\_r\\_\\_;\\textbackslash{}n        local\\_scalar\\_t\\_\\_ DUMMY\\_VAR\\_\\_(std::numeric\\_limits<double>::quiet\\_NaN());\\textbackslash{}n        (void) DUMMY\\_VAR\\_\\_;  // suppress unused var warning\\textbackslash{}n\\textbackslash{}n        // initialize member variables\\textbackslash{}n        try \\{\\textbackslash{}n            current\\_statement\\_begin\\_\\_ = 4;\\textbackslash{}n            context\\_\\_.validate\\_dims(\"data initialization\", \"N\", \"int\", context\\_\\_.to\\_vec());\\textbackslash{}n            N = int(0);\\textbackslash{}n            vals\\_i\\_\\_ = context\\_\\_.vals\\_i(\"N\");\\textbackslash{}n            pos\\_\\_ = 0;\\textbackslash{}n            N = vals\\_i\\_\\_{[}pos\\_\\_++{]};\\textbackslash{}n            current\\_statement\\_begin\\_\\_ = 5;\\textbackslash{}n            validate\\_non\\_negative\\_index(\"x\", \"N\", N);\\textbackslash{}n            context\\_\\_.validate\\_dims(\"data initialization\", \"x\", \"vector\\_d\", context\\_\\_.to\\_vec(N));\\textbackslash{}n            validate\\_non\\_negative\\_index(\"x\", \"N\", N);\\textbackslash{}n            x = vector\\_d(static\\_cast<Eigen::VectorXd::Index>(N));\\textbackslash{}n            vals\\_r\\_\\_ = context\\_\\_.vals\\_r(\"x\");\\textbackslash{}n            pos\\_\\_ = 0;\\textbackslash{}n            size\\_t x\\_i\\_vec\\_lim\\_\\_ = N;\\textbackslash{}n            for (size\\_t i\\_vec\\_\\_ = 0; i\\_vec\\_\\_ < x\\_i\\_vec\\_lim\\_\\_; ++i\\_vec\\_\\_) \\{\\textbackslash{}n                x{[}i\\_vec\\_\\_{]} = vals\\_r\\_\\_{[}pos\\_\\_++{]};\\textbackslash{}n            \\}\\textbackslash{}n            current\\_statement\\_begin\\_\\_ = 6;\\textbackslash{}n            validate\\_non\\_negative\\_index(\"y\", \"N\", N);\\textbackslash{}n            context\\_\\_.validate\\_dims(\"data initialization\", \"y\", \"vector\\_d\", context\\_\\_.to\\_vec(N));\\textbackslash{}n            validate\\_non\\_negative\\_index(\"y\", \"N\", N);\\textbackslash{}n            y = vector\\_d(static\\_cast<Eigen::VectorXd::Index>(N));\\textbackslash{}n            vals\\_r\\_\\_ = context\\_\\_.vals\\_r(\"y\");\\textbackslash{}n            pos\\_\\_ = 0;\\textbackslash{}n            size\\_t y\\_i\\_vec\\_lim\\_\\_ = N;\\textbackslash{}n            for (size\\_t i\\_vec\\_\\_ = 0; i\\_vec\\_\\_ < y\\_i\\_vec\\_lim\\_\\_; ++i\\_vec\\_\\_) \\{\\textbackslash{}n                y{[}i\\_vec\\_\\_{]} = vals\\_r\\_\\_{[}pos\\_\\_++{]};\\textbackslash{}n            \\}\\textbackslash{}n\\textbackslash{}n            // validate, data variables\\textbackslash{}n            current\\_statement\\_begin\\_\\_ = 4;\\textbackslash{}n            check\\_greater\\_or\\_equal(function\\_\\_,\"N\",N,1);\\textbackslash{}n            current\\_statement\\_begin\\_\\_ = 5;\\textbackslash{}n            current\\_statement\\_begin\\_\\_ = 6;\\textbackslash{}n            // initialize data variables\\textbackslash{}n\\textbackslash{}n\\textbackslash{}n            // validate transformed data\\textbackslash{}n\\textbackslash{}n            // validate, set parameter ranges\\textbackslash{}n            num\\_params\\_r\\_\\_ = 0U;\\textbackslash{}n            param\\_ranges\\_i\\_\\_.clear();\\textbackslash{}n            current\\_statement\\_begin\\_\\_ = 10;\\textbackslash{}n            ++num\\_params\\_r\\_\\_;\\textbackslash{}n            current\\_statement\\_begin\\_\\_ = 11;\\textbackslash{}n            ++num\\_params\\_r\\_\\_;\\textbackslash{}n            current\\_statement\\_begin\\_\\_ = 12;\\textbackslash{}n            ++num\\_params\\_r\\_\\_;\\textbackslash{}n        \\} catch (const std::exception\\& e) \\{\\textbackslash{}n            stan::lang::rethrow\\_located(e, current\\_statement\\_begin\\_\\_, prog\\_reader\\_\\_());\\textbackslash{}n            // Next line prevents compiler griping about no return\\textbackslash{}n            throw std::runtime\\_error(\"*** IF YOU SEE THIS, PLEASE REPORT A BUG ***\");\\textbackslash{}n        \\}\\textbackslash{}n    \\}\\textbackslash{}n\\textbackslash{}n    \\textasciitilde{}model4fa476daf76\\_stan\\_model1() \\{ \\}\\textbackslash{}n\\textbackslash{}n\\textbackslash{}n    void transform\\_inits(const stan::io::var\\_context\\& context\\_\\_,\\textbackslash{}n                         std::vector<int>\\& params\\_i\\_\\_,\\textbackslash{}n                         std::vector<double>\\& params\\_r\\_\\_,\\textbackslash{}n                         std::ostream* pstream\\_\\_) const \\{\\textbackslash{}n        stan::io::writer<double> writer\\_\\_(params\\_r\\_\\_,params\\_i\\_\\_);\\textbackslash{}n        size\\_t pos\\_\\_;\\textbackslash{}n        (void) pos\\_\\_; // dummy call to supress warning\\textbackslash{}n        std::vector<double> vals\\_r\\_\\_;\\textbackslash{}n        std::vector<int> vals\\_i\\_\\_;\\textbackslash{}n\\textbackslash{}n        if (!(context\\_\\_.contains\\_r(\"alpha\")))\\textbackslash{}n            throw std::runtime\\_error(\"variable alpha missing\");\\textbackslash{}n        vals\\_r\\_\\_ = context\\_\\_.vals\\_r(\"alpha\");\\textbackslash{}n        pos\\_\\_ = 0U;\\textbackslash{}n        context\\_\\_.validate\\_dims(\"initialization\", \"alpha\", \"double\", context\\_\\_.to\\_vec());\\textbackslash{}n        double alpha(0);\\textbackslash{}n        alpha = vals\\_r\\_\\_{[}pos\\_\\_++{]};\\textbackslash{}n        try \\{\\textbackslash{}n            writer\\_\\_.scalar\\_unconstrain(alpha);\\textbackslash{}n        \\} catch (const std::exception\\& e) \\{ \\textbackslash{}n            throw std::runtime\\_error(std::string(\"Error transforming variable alpha: \") + e.what());\\textbackslash{}n        \\}\\textbackslash{}n\\textbackslash{}n        if (!(context\\_\\_.contains\\_r(\"beta\")))\\textbackslash{}n            throw std::runtime\\_error(\"variable beta missing\");\\textbackslash{}n        vals\\_r\\_\\_ = context\\_\\_.vals\\_r(\"beta\");\\textbackslash{}n        pos\\_\\_ = 0U;\\textbackslash{}n        context\\_\\_.validate\\_dims(\"initialization\", \"beta\", \"double\", context\\_\\_.to\\_vec());\\textbackslash{}n        double beta(0);\\textbackslash{}n        beta = vals\\_r\\_\\_{[}pos\\_\\_++{]};\\textbackslash{}n        try \\{\\textbackslash{}n            writer\\_\\_.scalar\\_unconstrain(beta);\\textbackslash{}n        \\} catch (const std::exception\\& e) \\{ \\textbackslash{}n            throw std::runtime\\_error(std::string(\"Error transforming variable beta: \") + e.what());\\textbackslash{}n        \\}\\textbackslash{}n\\textbackslash{}n        if (!(context\\_\\_.contains\\_r(\"sigma\")))\\textbackslash{}n            throw std::runtime\\_error(\"variable sigma missing\");\\textbackslash{}n        vals\\_r\\_\\_ = context\\_\\_.vals\\_r(\"sigma\");\\textbackslash{}n        pos\\_\\_ = 0U;\\textbackslash{}n        context\\_\\_.validate\\_dims(\"initialization\", \"sigma\", \"double\", context\\_\\_.to\\_vec());\\textbackslash{}n        double sigma(0);\\textbackslash{}n        sigma = vals\\_r\\_\\_{[}pos\\_\\_++{]};\\textbackslash{}n        try \\{\\textbackslash{}n            writer\\_\\_.scalar\\_lb\\_unconstrain(0,sigma);\\textbackslash{}n        \\} catch (const std::exception\\& e) \\{ \\textbackslash{}n            throw std::runtime\\_error(std::string(\"Error transforming variable sigma: \") + e.what());\\textbackslash{}n        \\}\\textbackslash{}n\\textbackslash{}n        params\\_r\\_\\_ = writer\\_\\_.data\\_r();\\textbackslash{}n        params\\_i\\_\\_ = writer\\_\\_.data\\_i();\\textbackslash{}n    \\}\\textbackslash{}n\\textbackslash{}n    void transform\\_inits(const stan::io::var\\_context\\& context,\\textbackslash{}n                         Eigen::Matrix<double,Eigen::Dynamic,1>\\& params\\_r,\\textbackslash{}n                         std::ostream* pstream\\_\\_) const \\{\\textbackslash{}n      std::vector<double> params\\_r\\_vec;\\textbackslash{}n      std::vector<int> params\\_i\\_vec;\\textbackslash{}n      transform\\_inits(context, params\\_i\\_vec, params\\_r\\_vec, pstream\\_\\_);\\textbackslash{}n      params\\_r.resize(params\\_r\\_vec.size());\\textbackslash{}n      for (int i = 0; i < params\\_r.size(); ++i)\\textbackslash{}n        params\\_r(i) = params\\_r\\_vec{[}i{]};\\textbackslash{}n    \\}\\textbackslash{}n\\textbackslash{}n\\textbackslash{}n    template <bool propto\\_\\_, bool jacobian\\_\\_, typename T\\_\\_>\\textbackslash{}n    T\\_\\_ log\\_prob(vector<T\\_\\_>\\& params\\_r\\_\\_,\\textbackslash{}n                 vector<int>\\& params\\_i\\_\\_,\\textbackslash{}n                 std::ostream* pstream\\_\\_ = 0) const \\{\\textbackslash{}n\\textbackslash{}n        typedef T\\_\\_ local\\_scalar\\_t\\_\\_;\\textbackslash{}n\\textbackslash{}n        local\\_scalar\\_t\\_\\_ DUMMY\\_VAR\\_\\_(std::numeric\\_limits<double>::quiet\\_NaN());\\textbackslash{}n        (void) DUMMY\\_VAR\\_\\_;  // suppress unused var warning\\textbackslash{}n\\textbackslash{}n        T\\_\\_ lp\\_\\_(0.0);\\textbackslash{}n        stan::math::accumulator<T\\_\\_> lp\\_accum\\_\\_;\\textbackslash{}n\\textbackslash{}n        try \\{\\textbackslash{}n            // model parameters\\textbackslash{}n            stan::io::reader<local\\_scalar\\_t\\_\\_> in\\_\\_(params\\_r\\_\\_,params\\_i\\_\\_);\\textbackslash{}n\\textbackslash{}n            local\\_scalar\\_t\\_\\_ alpha;\\textbackslash{}n            (void) alpha;  // dummy to suppress unused var warning\\textbackslash{}n            if (jacobian\\_\\_)\\textbackslash{}n                alpha = in\\_\\_.scalar\\_constrain(lp\\_\\_);\\textbackslash{}n            else\\textbackslash{}n                alpha = in\\_\\_.scalar\\_constrain();\\textbackslash{}n\\textbackslash{}n            local\\_scalar\\_t\\_\\_ beta;\\textbackslash{}n            (void) beta;  // dummy to suppress unused var warning\\textbackslash{}n            if (jacobian\\_\\_)\\textbackslash{}n                beta = in\\_\\_.scalar\\_constrain(lp\\_\\_);\\textbackslash{}n            else\\textbackslash{}n                beta = in\\_\\_.scalar\\_constrain();\\textbackslash{}n\\textbackslash{}n            local\\_scalar\\_t\\_\\_ sigma;\\textbackslash{}n            (void) sigma;  // dummy to suppress unused var warning\\textbackslash{}n            if (jacobian\\_\\_)\\textbackslash{}n                sigma = in\\_\\_.scalar\\_lb\\_constrain(0,lp\\_\\_);\\textbackslash{}n            else\\textbackslash{}n                sigma = in\\_\\_.scalar\\_lb\\_constrain(0);\\textbackslash{}n\\textbackslash{}n\\textbackslash{}n            // transformed parameters\\textbackslash{}n\\textbackslash{}n\\textbackslash{}n\\textbackslash{}n            // validate transformed parameters\\textbackslash{}n\\textbackslash{}n            const char* function\\_\\_ = \"validate transformed params\";\\textbackslash{}n            (void) function\\_\\_;  // dummy to suppress unused var warning\\textbackslash{}n\\textbackslash{}n            // model body\\textbackslash{}n\\textbackslash{}n            current\\_statement\\_begin\\_\\_ = 16;\\textbackslash{}n            lp\\_accum\\_\\_.add(normal\\_log<propto\\_\\_>(y, add(alpha,multiply(x,beta)), sigma));\\textbackslash{}n\\textbackslash{}n        \\} catch (const std::exception\\& e) \\{\\textbackslash{}n            stan::lang::rethrow\\_located(e, current\\_statement\\_begin\\_\\_, prog\\_reader\\_\\_());\\textbackslash{}n            // Next line prevents compiler griping about no return\\textbackslash{}n            throw std::runtime\\_error(\"*** IF YOU SEE THIS, PLEASE REPORT A BUG ***\");\\textbackslash{}n        \\}\\textbackslash{}n\\textbackslash{}n        lp\\_accum\\_\\_.add(lp\\_\\_);\\textbackslash{}n        return lp\\_accum\\_\\_.sum();\\textbackslash{}n\\textbackslash{}n    \\} // log\\_prob()\\textbackslash{}n\\textbackslash{}n    template <bool propto, bool jacobian, typename T\\_>\\textbackslash{}n    T\\_ log\\_prob(Eigen::Matrix<T\\_,Eigen::Dynamic,1>\\& params\\_r,\\textbackslash{}n               std::ostream* pstream = 0) const \\{\\textbackslash{}n      std::vector<T\\_> vec\\_params\\_r;\\textbackslash{}n      vec\\_params\\_r.reserve(params\\_r.size());\\textbackslash{}n      for (int i = 0; i < params\\_r.size(); ++i)\\textbackslash{}n        vec\\_params\\_r.push\\_back(params\\_r(i));\\textbackslash{}n      std::vector<int> vec\\_params\\_i;\\textbackslash{}n      return log\\_prob<propto,jacobian,T\\_>(vec\\_params\\_r, vec\\_params\\_i, pstream);\\textbackslash{}n    \\}\\textbackslash{}n\\textbackslash{}n\\textbackslash{}n    void get\\_param\\_names(std::vector<std::string>\\& names\\_\\_) const \\{\\textbackslash{}n        names\\_\\_.resize(0);\\textbackslash{}n        names\\_\\_.push\\_back(\"alpha\");\\textbackslash{}n        names\\_\\_.push\\_back(\"beta\");\\textbackslash{}n        names\\_\\_.push\\_back(\"sigma\");\\textbackslash{}n    \\}\\textbackslash{}n\\textbackslash{}n\\textbackslash{}n    void get\\_dims(std::vector<std::vector<size\\_t> >\\& dimss\\_\\_) const \\{\\textbackslash{}n        dimss\\_\\_.resize(0);\\textbackslash{}n        std::vector<size\\_t> dims\\_\\_;\\textbackslash{}n        dims\\_\\_.resize(0);\\textbackslash{}n        dimss\\_\\_.push\\_back(dims\\_\\_);\\textbackslash{}n        dims\\_\\_.resize(0);\\textbackslash{}n        dimss\\_\\_.push\\_back(dims\\_\\_);\\textbackslash{}n        dims\\_\\_.resize(0);\\textbackslash{}n        dimss\\_\\_.push\\_back(dims\\_\\_);\\textbackslash{}n    \\}\\textbackslash{}n\\textbackslash{}n    template <typename RNG>\\textbackslash{}n    void write\\_array(RNG\\& base\\_rng\\_\\_,\\textbackslash{}n                     std::vector<double>\\& params\\_r\\_\\_,\\textbackslash{}n                     std::vector<int>\\& params\\_i\\_\\_,\\textbackslash{}n                     std::vector<double>\\& vars\\_\\_,\\textbackslash{}n                     bool include\\_tparams\\_\\_ = true,\\textbackslash{}n                     bool include\\_gqs\\_\\_ = true,\\textbackslash{}n                     std::ostream* pstream\\_\\_ = 0) const \\{\\textbackslash{}n        typedef double local\\_scalar\\_t\\_\\_;\\textbackslash{}n\\textbackslash{}n        vars\\_\\_.resize(0);\\textbackslash{}n        stan::io::reader<local\\_scalar\\_t\\_\\_> in\\_\\_(params\\_r\\_\\_,params\\_i\\_\\_);\\textbackslash{}n        static const char* function\\_\\_ = \"model4fa476daf76\\_stan\\_model1\\_namespace::write\\_array\";\\textbackslash{}n        (void) function\\_\\_;  // dummy to suppress unused var warning\\textbackslash{}n        // read-transform, write parameters\\textbackslash{}n        double alpha = in\\_\\_.scalar\\_constrain();\\textbackslash{}n        double beta = in\\_\\_.scalar\\_constrain();\\textbackslash{}n        double sigma = in\\_\\_.scalar\\_lb\\_constrain(0);\\textbackslash{}n        vars\\_\\_.push\\_back(alpha);\\textbackslash{}n        vars\\_\\_.push\\_back(beta);\\textbackslash{}n        vars\\_\\_.push\\_back(sigma);\\textbackslash{}n\\textbackslash{}n        // declare and define transformed parameters\\textbackslash{}n        double lp\\_\\_ = 0.0;\\textbackslash{}n        (void) lp\\_\\_;  // dummy to suppress unused var warning\\textbackslash{}n        stan::math::accumulator<double> lp\\_accum\\_\\_;\\textbackslash{}n\\textbackslash{}n        local\\_scalar\\_t\\_\\_ DUMMY\\_VAR\\_\\_(std::numeric\\_limits<double>::quiet\\_NaN());\\textbackslash{}n        (void) DUMMY\\_VAR\\_\\_;  // suppress unused var warning\\textbackslash{}n\\textbackslash{}n        try \\{\\textbackslash{}n\\textbackslash{}n\\textbackslash{}n\\textbackslash{}n            // validate transformed parameters\\textbackslash{}n\\textbackslash{}n            // write transformed parameters\\textbackslash{}n            if (include\\_tparams\\_\\_) \\{\\textbackslash{}n            \\}\\textbackslash{}n            if (!include\\_gqs\\_\\_) return;\\textbackslash{}n            // declare and define generated quantities\\textbackslash{}n\\textbackslash{}n\\textbackslash{}n\\textbackslash{}n            // validate generated quantities\\textbackslash{}n\\textbackslash{}n            // write generated quantities\\textbackslash{}n        \\} catch (const std::exception\\& e) \\{\\textbackslash{}n            stan::lang::rethrow\\_located(e, current\\_statement\\_begin\\_\\_, prog\\_reader\\_\\_());\\textbackslash{}n            // Next line prevents compiler griping about no return\\textbackslash{}n            throw std::runtime\\_error(\"*** IF YOU SEE THIS, PLEASE REPORT A BUG ***\");\\textbackslash{}n        \\}\\textbackslash{}n    \\}\\textbackslash{}n\\textbackslash{}n    template <typename RNG>\\textbackslash{}n    void write\\_array(RNG\\& base\\_rng,\\textbackslash{}n                     Eigen::Matrix<double,Eigen::Dynamic,1>\\& params\\_r,\\textbackslash{}n                     Eigen::Matrix<double,Eigen::Dynamic,1>\\& vars,\\textbackslash{}n                     bool include\\_tparams = true,\\textbackslash{}n                     bool include\\_gqs = true,\\textbackslash{}n                     std::ostream* pstream = 0) const \\{\\textbackslash{}n      std::vector<double> params\\_r\\_vec(params\\_r.size());\\textbackslash{}n      for (int i = 0; i < params\\_r.size(); ++i)\\textbackslash{}n        params\\_r\\_vec{[}i{]} = params\\_r(i);\\textbackslash{}n      std::vector<double> vars\\_vec;\\textbackslash{}n      std::vector<int> params\\_i\\_vec;\\textbackslash{}n      write\\_array(base\\_rng,params\\_r\\_vec,params\\_i\\_vec,vars\\_vec,include\\_tparams,include\\_gqs,pstream);\\textbackslash{}n      vars.resize(vars\\_vec.size());\\textbackslash{}n      for (int i = 0; i < vars.size(); ++i)\\textbackslash{}n        vars(i) = vars\\_vec{[}i{]};\\textbackslash{}n    \\}\\textbackslash{}n\\textbackslash{}n    static std::string model\\_name() \\{\\textbackslash{}n        return \"model4fa476daf76\\_stan\\_model1\";\\textbackslash{}n    \\}\\textbackslash{}n\\textbackslash{}n\\textbackslash{}n    void constrained\\_param\\_names(std::vector<std::string>\\& param\\_names\\_\\_,\\textbackslash{}n                                 bool include\\_tparams\\_\\_ = true,\\textbackslash{}n                                 bool include\\_gqs\\_\\_ = true) const \\{\\textbackslash{}n        std::stringstream param\\_name\\_stream\\_\\_;\\textbackslash{}n        param\\_name\\_stream\\_\\_.str(std::string());\\textbackslash{}n        param\\_name\\_stream\\_\\_ << \"alpha\";\\textbackslash{}n        param\\_names\\_\\_.push\\_back(param\\_name\\_stream\\_\\_.str());\\textbackslash{}n        param\\_name\\_stream\\_\\_.str(std::string());\\textbackslash{}n        param\\_name\\_stream\\_\\_ << \"beta\";\\textbackslash{}n        param\\_names\\_\\_.push\\_back(param\\_name\\_stream\\_\\_.str());\\textbackslash{}n        param\\_name\\_stream\\_\\_.str(std::string());\\textbackslash{}n        param\\_name\\_stream\\_\\_ << \"sigma\";\\textbackslash{}n        param\\_names\\_\\_.push\\_back(param\\_name\\_stream\\_\\_.str());\\textbackslash{}n\\textbackslash{}n        if (!include\\_gqs\\_\\_ \\&\\& !include\\_tparams\\_\\_) return;\\textbackslash{}n\\textbackslash{}n        if (include\\_tparams\\_\\_) \\{\\textbackslash{}n        \\}\\textbackslash{}n\\textbackslash{}n\\textbackslash{}n        if (!include\\_gqs\\_\\_) return;\\textbackslash{}n    \\}\\textbackslash{}n\\textbackslash{}n\\textbackslash{}n    void unconstrained\\_param\\_names(std::vector<std::string>\\& param\\_names\\_\\_,\\textbackslash{}n                                   bool include\\_tparams\\_\\_ = true,\\textbackslash{}n                                   bool include\\_gqs\\_\\_ = true) const \\{\\textbackslash{}n        std::stringstream param\\_name\\_stream\\_\\_;\\textbackslash{}n        param\\_name\\_stream\\_\\_.str(std::string());\\textbackslash{}n        param\\_name\\_stream\\_\\_ << \"alpha\";\\textbackslash{}n        param\\_names\\_\\_.push\\_back(param\\_name\\_stream\\_\\_.str());\\textbackslash{}n        param\\_name\\_stream\\_\\_.str(std::string());\\textbackslash{}n        param\\_name\\_stream\\_\\_ << \"beta\";\\textbackslash{}n        param\\_names\\_\\_.push\\_back(param\\_name\\_stream\\_\\_.str());\\textbackslash{}n        param\\_name\\_stream\\_\\_.str(std::string());\\textbackslash{}n        param\\_name\\_stream\\_\\_ << \"sigma\";\\textbackslash{}n        param\\_names\\_\\_.push\\_back(param\\_name\\_stream\\_\\_.str());\\textbackslash{}n\\textbackslash{}n        if (!include\\_gqs\\_\\_ \\&\\& !include\\_tparams\\_\\_) return;\\textbackslash{}n\\textbackslash{}n        if (include\\_tparams\\_\\_) \\{\\textbackslash{}n        \\}\\textbackslash{}n\\textbackslash{}n\\textbackslash{}n        if (!include\\_gqs\\_\\_) return;\\textbackslash{}n    \\}\\textbackslash{}n\\textbackslash{}n\\}; // model\\textbackslash{}n\\textbackslash{}n\\}\\textbackslash{}n\\textbackslash{}ntypedef model4fa476daf76\\_stan\\_model1\\_namespace::model4fa476daf76\\_stan\\_model1 stan\\_model;\\textbackslash{}n\\textbackslash{}n'\n",
       "\\item[\\$model\\_name] 'stan\\_model1'\n",
       "\\item[\\$model\\_code] '// Stan model for simple linear regression\\textbackslash{}n\\textbackslash{}ndata \\{\\textbackslash{}n int < lower = 1 > N; // Sample size is an integer with the lowest value of 1 (i.e. positive)\\textbackslash{}n vector{[}N{]} x; // Predictor is a vector of the size of sample size\\textbackslash{}n vector{[}N{]} y; // Outcome is a vector of a size of sample size\\textbackslash{}n\\}\\textbackslash{}n\\textbackslash{}nparameters \\{\\textbackslash{}n real alpha; // Intercept is an unconstrained continous value\\textbackslash{}n real beta; // Slope (regression coefficients) is an unconstrained continous value\\textbackslash{}n real < lower = 0 > sigma; // Error SD is an unconstrained positive continous valeu\\textbackslash{}n\\}\\textbackslash{}n\\textbackslash{}nmodel \\{\\textbackslash{}n y \\textasciitilde{} normal(alpha + x * beta , sigma); //this seem to declare the model\\textbackslash{}n\\}\\textbackslash{}ngenerated quantities \\{\\textbackslash{}n\\} // The posterior predictive distribution'\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$status\n",
       ":   TRUE\n",
       "$model_cppname\n",
       ":   'model4fa476daf76_stan_model1'\n",
       "$cppcode\n",
       ":   <span style=white-space:pre-wrap>'// Code generated by Stan version 2.18.1\\n\\n#include &lt;stan/model/model_header.hpp&gt;\\n\\nnamespace model4fa476daf76_stan_model1_namespace {\\n\\nusing std::istream;\\nusing std::string;\\nusing std::stringstream;\\nusing std::vector;\\nusing stan::io::dump;\\nusing stan::math::lgamma;\\nusing stan::model::prob_grad;\\nusing namespace stan::math;\\n\\nstatic int current_statement_begin__;\\n\\nstan::io::program_reader prog_reader__() {\\n    stan::io::program_reader reader;\\n    reader.add_event(0, 0, \"start\", \"model4fa476daf76_stan_model1\");\\n    reader.add_event(21, 19, \"end\", \"model4fa476daf76_stan_model1\");\\n    return reader;\\n}\\n\\nclass model4fa476daf76_stan_model1 : public prob_grad {\\nprivate:\\n    int N;\\n    vector_d x;\\n    vector_d y;\\npublic:\\n    model4fa476daf76_stan_model1(stan::io::var_context&amp; context__,\\n        std::ostream* pstream__ = 0)\\n        : prob_grad(0) {\\n        ctor_body(context__, 0, pstream__);\\n    }\\n\\n    model4fa476daf76_stan_model1(stan::io::var_context&amp; context__,\\n        unsigned int random_seed__,\\n        std::ostream* pstream__ = 0)\\n        : prob_grad(0) {\\n        ctor_body(context__, random_seed__, pstream__);\\n    }\\n\\n    void ctor_body(stan::io::var_context&amp; context__,\\n                   unsigned int random_seed__,\\n                   std::ostream* pstream__) {\\n        typedef double local_scalar_t__;\\n\\n        boost::ecuyer1988 base_rng__ =\\n          stan::services::util::create_rng(random_seed__, 0);\\n        (void) base_rng__;  // suppress unused var warning\\n\\n        current_statement_begin__ = -1;\\n\\n        static const char* function__ = \"model4fa476daf76_stan_model1_namespace::model4fa476daf76_stan_model1\";\\n        (void) function__;  // dummy to suppress unused var warning\\n        size_t pos__;\\n        (void) pos__;  // dummy to suppress unused var warning\\n        std::vector&lt;int&gt; vals_i__;\\n        std::vector&lt;double&gt; vals_r__;\\n        local_scalar_t__ DUMMY_VAR__(std::numeric_limits&lt;double&gt;::quiet_NaN());\\n        (void) DUMMY_VAR__;  // suppress unused var warning\\n\\n        // initialize member variables\\n        try {\\n            current_statement_begin__ = 4;\\n            context__.validate_dims(\"data initialization\", \"N\", \"int\", context__.to_vec());\\n            N = int(0);\\n            vals_i__ = context__.vals_i(\"N\");\\n            pos__ = 0;\\n            N = vals_i__[pos__++];\\n            current_statement_begin__ = 5;\\n            validate_non_negative_index(\"x\", \"N\", N);\\n            context__.validate_dims(\"data initialization\", \"x\", \"vector_d\", context__.to_vec(N));\\n            validate_non_negative_index(\"x\", \"N\", N);\\n            x = vector_d(static_cast&lt;Eigen::VectorXd::Index&gt;(N));\\n            vals_r__ = context__.vals_r(\"x\");\\n            pos__ = 0;\\n            size_t x_i_vec_lim__ = N;\\n            for (size_t i_vec__ = 0; i_vec__ &lt; x_i_vec_lim__; ++i_vec__) {\\n                x[i_vec__] = vals_r__[pos__++];\\n            }\\n            current_statement_begin__ = 6;\\n            validate_non_negative_index(\"y\", \"N\", N);\\n            context__.validate_dims(\"data initialization\", \"y\", \"vector_d\", context__.to_vec(N));\\n            validate_non_negative_index(\"y\", \"N\", N);\\n            y = vector_d(static_cast&lt;Eigen::VectorXd::Index&gt;(N));\\n            vals_r__ = context__.vals_r(\"y\");\\n            pos__ = 0;\\n            size_t y_i_vec_lim__ = N;\\n            for (size_t i_vec__ = 0; i_vec__ &lt; y_i_vec_lim__; ++i_vec__) {\\n                y[i_vec__] = vals_r__[pos__++];\\n            }\\n\\n            // validate, data variables\\n            current_statement_begin__ = 4;\\n            check_greater_or_equal(function__,\"N\",N,1);\\n            current_statement_begin__ = 5;\\n            current_statement_begin__ = 6;\\n            // initialize data variables\\n\\n\\n            // validate transformed data\\n\\n            // validate, set parameter ranges\\n            num_params_r__ = 0U;\\n            param_ranges_i__.clear();\\n            current_statement_begin__ = 10;\\n            ++num_params_r__;\\n            current_statement_begin__ = 11;\\n            ++num_params_r__;\\n            current_statement_begin__ = 12;\\n            ++num_params_r__;\\n        } catch (const std::exception&amp; e) {\\n            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());\\n            // Next line prevents compiler griping about no return\\n            throw std::runtime_error(\"*** IF YOU SEE THIS, PLEASE REPORT A BUG ***\");\\n        }\\n    }\\n\\n    ~model4fa476daf76_stan_model1() { }\\n\\n\\n    void transform_inits(const stan::io::var_context&amp; context__,\\n                         std::vector&lt;int&gt;&amp; params_i__,\\n                         std::vector&lt;double&gt;&amp; params_r__,\\n                         std::ostream* pstream__) const {\\n        stan::io::writer&lt;double&gt; writer__(params_r__,params_i__);\\n        size_t pos__;\\n        (void) pos__; // dummy call to supress warning\\n        std::vector&lt;double&gt; vals_r__;\\n        std::vector&lt;int&gt; vals_i__;\\n\\n        if (!(context__.contains_r(\"alpha\")))\\n            throw std::runtime_error(\"variable alpha missing\");\\n        vals_r__ = context__.vals_r(\"alpha\");\\n        pos__ = 0U;\\n        context__.validate_dims(\"initialization\", \"alpha\", \"double\", context__.to_vec());\\n        double alpha(0);\\n        alpha = vals_r__[pos__++];\\n        try {\\n            writer__.scalar_unconstrain(alpha);\\n        } catch (const std::exception&amp; e) { \\n            throw std::runtime_error(std::string(\"Error transforming variable alpha: \") + e.what());\\n        }\\n\\n        if (!(context__.contains_r(\"beta\")))\\n            throw std::runtime_error(\"variable beta missing\");\\n        vals_r__ = context__.vals_r(\"beta\");\\n        pos__ = 0U;\\n        context__.validate_dims(\"initialization\", \"beta\", \"double\", context__.to_vec());\\n        double beta(0);\\n        beta = vals_r__[pos__++];\\n        try {\\n            writer__.scalar_unconstrain(beta);\\n        } catch (const std::exception&amp; e) { \\n            throw std::runtime_error(std::string(\"Error transforming variable beta: \") + e.what());\\n        }\\n\\n        if (!(context__.contains_r(\"sigma\")))\\n            throw std::runtime_error(\"variable sigma missing\");\\n        vals_r__ = context__.vals_r(\"sigma\");\\n        pos__ = 0U;\\n        context__.validate_dims(\"initialization\", \"sigma\", \"double\", context__.to_vec());\\n        double sigma(0);\\n        sigma = vals_r__[pos__++];\\n        try {\\n            writer__.scalar_lb_unconstrain(0,sigma);\\n        } catch (const std::exception&amp; e) { \\n            throw std::runtime_error(std::string(\"Error transforming variable sigma: \") + e.what());\\n        }\\n\\n        params_r__ = writer__.data_r();\\n        params_i__ = writer__.data_i();\\n    }\\n\\n    void transform_inits(const stan::io::var_context&amp; context,\\n                         Eigen::Matrix&lt;double,Eigen::Dynamic,1&gt;&amp; params_r,\\n                         std::ostream* pstream__) const {\\n      std::vector&lt;double&gt; params_r_vec;\\n      std::vector&lt;int&gt; params_i_vec;\\n      transform_inits(context, params_i_vec, params_r_vec, pstream__);\\n      params_r.resize(params_r_vec.size());\\n      for (int i = 0; i &lt; params_r.size(); ++i)\\n        params_r(i) = params_r_vec[i];\\n    }\\n\\n\\n    template &lt;bool propto__, bool jacobian__, typename T__&gt;\\n    T__ log_prob(vector&lt;T__&gt;&amp; params_r__,\\n                 vector&lt;int&gt;&amp; params_i__,\\n                 std::ostream* pstream__ = 0) const {\\n\\n        typedef T__ local_scalar_t__;\\n\\n        local_scalar_t__ DUMMY_VAR__(std::numeric_limits&lt;double&gt;::quiet_NaN());\\n        (void) DUMMY_VAR__;  // suppress unused var warning\\n\\n        T__ lp__(0.0);\\n        stan::math::accumulator&lt;T__&gt; lp_accum__;\\n\\n        try {\\n            // model parameters\\n            stan::io::reader&lt;local_scalar_t__&gt; in__(params_r__,params_i__);\\n\\n            local_scalar_t__ alpha;\\n            (void) alpha;  // dummy to suppress unused var warning\\n            if (jacobian__)\\n                alpha = in__.scalar_constrain(lp__);\\n            else\\n                alpha = in__.scalar_constrain();\\n\\n            local_scalar_t__ beta;\\n            (void) beta;  // dummy to suppress unused var warning\\n            if (jacobian__)\\n                beta = in__.scalar_constrain(lp__);\\n            else\\n                beta = in__.scalar_constrain();\\n\\n            local_scalar_t__ sigma;\\n            (void) sigma;  // dummy to suppress unused var warning\\n            if (jacobian__)\\n                sigma = in__.scalar_lb_constrain(0,lp__);\\n            else\\n                sigma = in__.scalar_lb_constrain(0);\\n\\n\\n            // transformed parameters\\n\\n\\n\\n            // validate transformed parameters\\n\\n            const char* function__ = \"validate transformed params\";\\n            (void) function__;  // dummy to suppress unused var warning\\n\\n            // model body\\n\\n            current_statement_begin__ = 16;\\n            lp_accum__.add(normal_log&lt;propto__&gt;(y, add(alpha,multiply(x,beta)), sigma));\\n\\n        } catch (const std::exception&amp; e) {\\n            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());\\n            // Next line prevents compiler griping about no return\\n            throw std::runtime_error(\"*** IF YOU SEE THIS, PLEASE REPORT A BUG ***\");\\n        }\\n\\n        lp_accum__.add(lp__);\\n        return lp_accum__.sum();\\n\\n    } // log_prob()\\n\\n    template &lt;bool propto, bool jacobian, typename T_&gt;\\n    T_ log_prob(Eigen::Matrix&lt;T_,Eigen::Dynamic,1&gt;&amp; params_r,\\n               std::ostream* pstream = 0) const {\\n      std::vector&lt;T_&gt; vec_params_r;\\n      vec_params_r.reserve(params_r.size());\\n      for (int i = 0; i &lt; params_r.size(); ++i)\\n        vec_params_r.push_back(params_r(i));\\n      std::vector&lt;int&gt; vec_params_i;\\n      return log_prob&lt;propto,jacobian,T_&gt;(vec_params_r, vec_params_i, pstream);\\n    }\\n\\n\\n    void get_param_names(std::vector&lt;std::string&gt;&amp; names__) const {\\n        names__.resize(0);\\n        names__.push_back(\"alpha\");\\n        names__.push_back(\"beta\");\\n        names__.push_back(\"sigma\");\\n    }\\n\\n\\n    void get_dims(std::vector&lt;std::vector&lt;size_t&gt; &gt;&amp; dimss__) const {\\n        dimss__.resize(0);\\n        std::vector&lt;size_t&gt; dims__;\\n        dims__.resize(0);\\n        dimss__.push_back(dims__);\\n        dims__.resize(0);\\n        dimss__.push_back(dims__);\\n        dims__.resize(0);\\n        dimss__.push_back(dims__);\\n    }\\n\\n    template &lt;typename RNG&gt;\\n    void write_array(RNG&amp; base_rng__,\\n                     std::vector&lt;double&gt;&amp; params_r__,\\n                     std::vector&lt;int&gt;&amp; params_i__,\\n                     std::vector&lt;double&gt;&amp; vars__,\\n                     bool include_tparams__ = true,\\n                     bool include_gqs__ = true,\\n                     std::ostream* pstream__ = 0) const {\\n        typedef double local_scalar_t__;\\n\\n        vars__.resize(0);\\n        stan::io::reader&lt;local_scalar_t__&gt; in__(params_r__,params_i__);\\n        static const char* function__ = \"model4fa476daf76_stan_model1_namespace::write_array\";\\n        (void) function__;  // dummy to suppress unused var warning\\n        // read-transform, write parameters\\n        double alpha = in__.scalar_constrain();\\n        double beta = in__.scalar_constrain();\\n        double sigma = in__.scalar_lb_constrain(0);\\n        vars__.push_back(alpha);\\n        vars__.push_back(beta);\\n        vars__.push_back(sigma);\\n\\n        // declare and define transformed parameters\\n        double lp__ = 0.0;\\n        (void) lp__;  // dummy to suppress unused var warning\\n        stan::math::accumulator&lt;double&gt; lp_accum__;\\n\\n        local_scalar_t__ DUMMY_VAR__(std::numeric_limits&lt;double&gt;::quiet_NaN());\\n        (void) DUMMY_VAR__;  // suppress unused var warning\\n\\n        try {\\n\\n\\n\\n            // validate transformed parameters\\n\\n            // write transformed parameters\\n            if (include_tparams__) {\\n            }\\n            if (!include_gqs__) return;\\n            // declare and define generated quantities\\n\\n\\n\\n            // validate generated quantities\\n\\n            // write generated quantities\\n        } catch (const std::exception&amp; e) {\\n            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());\\n            // Next line prevents compiler griping about no return\\n            throw std::runtime_error(\"*** IF YOU SEE THIS, PLEASE REPORT A BUG ***\");\\n        }\\n    }\\n\\n    template &lt;typename RNG&gt;\\n    void write_array(RNG&amp; base_rng,\\n                     Eigen::Matrix&lt;double,Eigen::Dynamic,1&gt;&amp; params_r,\\n                     Eigen::Matrix&lt;double,Eigen::Dynamic,1&gt;&amp; vars,\\n                     bool include_tparams = true,\\n                     bool include_gqs = true,\\n                     std::ostream* pstream = 0) const {\\n      std::vector&lt;double&gt; params_r_vec(params_r.size());\\n      for (int i = 0; i &lt; params_r.size(); ++i)\\n        params_r_vec[i] = params_r(i);\\n      std::vector&lt;double&gt; vars_vec;\\n      std::vector&lt;int&gt; params_i_vec;\\n      write_array(base_rng,params_r_vec,params_i_vec,vars_vec,include_tparams,include_gqs,pstream);\\n      vars.resize(vars_vec.size());\\n      for (int i = 0; i &lt; vars.size(); ++i)\\n        vars(i) = vars_vec[i];\\n    }\\n\\n    static std::string model_name() {\\n        return \"model4fa476daf76_stan_model1\";\\n    }\\n\\n\\n    void constrained_param_names(std::vector&lt;std::string&gt;&amp; param_names__,\\n                                 bool include_tparams__ = true,\\n                                 bool include_gqs__ = true) const {\\n        std::stringstream param_name_stream__;\\n        param_name_stream__.str(std::string());\\n        param_name_stream__ &lt;&lt; \"alpha\";\\n        param_names__.push_back(param_name_stream__.str());\\n        param_name_stream__.str(std::string());\\n        param_name_stream__ &lt;&lt; \"beta\";\\n        param_names__.push_back(param_name_stream__.str());\\n        param_name_stream__.str(std::string());\\n        param_name_stream__ &lt;&lt; \"sigma\";\\n        param_names__.push_back(param_name_stream__.str());\\n\\n        if (!include_gqs__ &amp;&amp; !include_tparams__) return;\\n\\n        if (include_tparams__) {\\n        }\\n\\n\\n        if (!include_gqs__) return;\\n    }\\n\\n\\n    void unconstrained_param_names(std::vector&lt;std::string&gt;&amp; param_names__,\\n                                   bool include_tparams__ = true,\\n                                   bool include_gqs__ = true) const {\\n        std::stringstream param_name_stream__;\\n        param_name_stream__.str(std::string());\\n        param_name_stream__ &lt;&lt; \"alpha\";\\n        param_names__.push_back(param_name_stream__.str());\\n        param_name_stream__.str(std::string());\\n        param_name_stream__ &lt;&lt; \"beta\";\\n        param_names__.push_back(param_name_stream__.str());\\n        param_name_stream__.str(std::string());\\n        param_name_stream__ &lt;&lt; \"sigma\";\\n        param_names__.push_back(param_name_stream__.str());\\n\\n        if (!include_gqs__ &amp;&amp; !include_tparams__) return;\\n\\n        if (include_tparams__) {\\n        }\\n\\n\\n        if (!include_gqs__) return;\\n    }\\n\\n}; // model\\n\\n}\\n\\ntypedef model4fa476daf76_stan_model1_namespace::model4fa476daf76_stan_model1 stan_model;\\n\\n'</span>\n",
       "$model_name\n",
       ":   'stan_model1'\n",
       "$model_code\n",
       ":   '// Stan model for simple linear regression\\n\\ndata {\\n int &lt; lower = 1 &gt; N; // Sample size is an integer with the lowest value of 1 (i.e. positive)\\n vector[N] x; // Predictor is a vector of the size of sample size\\n vector[N] y; // Outcome is a vector of a size of sample size\\n}\\n\\nparameters {\\n real alpha; // Intercept is an unconstrained continous value\\n real beta; // Slope (regression coefficients) is an unconstrained continous value\\n real &lt; lower = 0 &gt; sigma; // Error SD is an unconstrained positive continous valeu\\n}\\n\\nmodel {\\n y ~ normal(alpha + x * beta , sigma); //this seem to declare the model\\n}\\ngenerated quantities {\\n} // The posterior predictive distribution'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$status\n",
       "[1] TRUE\n",
       "\n",
       "$model_cppname\n",
       "[1] \"model4fa476daf76_stan_model1\"\n",
       "\n",
       "$cppcode\n",
       "[1] \"// Code generated by Stan version 2.18.1\\n\\n#include <stan/model/model_header.hpp>\\n\\nnamespace model4fa476daf76_stan_model1_namespace {\\n\\nusing std::istream;\\nusing std::string;\\nusing std::stringstream;\\nusing std::vector;\\nusing stan::io::dump;\\nusing stan::math::lgamma;\\nusing stan::model::prob_grad;\\nusing namespace stan::math;\\n\\nstatic int current_statement_begin__;\\n\\nstan::io::program_reader prog_reader__() {\\n    stan::io::program_reader reader;\\n    reader.add_event(0, 0, \\\"start\\\", \\\"model4fa476daf76_stan_model1\\\");\\n    reader.add_event(21, 19, \\\"end\\\", \\\"model4fa476daf76_stan_model1\\\");\\n    return reader;\\n}\\n\\nclass model4fa476daf76_stan_model1 : public prob_grad {\\nprivate:\\n    int N;\\n    vector_d x;\\n    vector_d y;\\npublic:\\n    model4fa476daf76_stan_model1(stan::io::var_context& context__,\\n        std::ostream* pstream__ = 0)\\n        : prob_grad(0) {\\n        ctor_body(context__, 0, pstream__);\\n    }\\n\\n    model4fa476daf76_stan_model1(stan::io::var_context& context__,\\n        unsigned int random_seed__,\\n        std::ostream* pstream__ = 0)\\n        : prob_grad(0) {\\n        ctor_body(context__, random_seed__, pstream__);\\n    }\\n\\n    void ctor_body(stan::io::var_context& context__,\\n                   unsigned int random_seed__,\\n                   std::ostream* pstream__) {\\n        typedef double local_scalar_t__;\\n\\n        boost::ecuyer1988 base_rng__ =\\n          stan::services::util::create_rng(random_seed__, 0);\\n        (void) base_rng__;  // suppress unused var warning\\n\\n        current_statement_begin__ = -1;\\n\\n        static const char* function__ = \\\"model4fa476daf76_stan_model1_namespace::model4fa476daf76_stan_model1\\\";\\n        (void) function__;  // dummy to suppress unused var warning\\n        size_t pos__;\\n        (void) pos__;  // dummy to suppress unused var warning\\n        std::vector<int> vals_i__;\\n        std::vector<double> vals_r__;\\n        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());\\n        (void) DUMMY_VAR__;  // suppress unused var warning\\n\\n        // initialize member variables\\n        try {\\n            current_statement_begin__ = 4;\\n            context__.validate_dims(\\\"data initialization\\\", \\\"N\\\", \\\"int\\\", context__.to_vec());\\n            N = int(0);\\n            vals_i__ = context__.vals_i(\\\"N\\\");\\n            pos__ = 0;\\n            N = vals_i__[pos__++];\\n            current_statement_begin__ = 5;\\n            validate_non_negative_index(\\\"x\\\", \\\"N\\\", N);\\n            context__.validate_dims(\\\"data initialization\\\", \\\"x\\\", \\\"vector_d\\\", context__.to_vec(N));\\n            validate_non_negative_index(\\\"x\\\", \\\"N\\\", N);\\n            x = vector_d(static_cast<Eigen::VectorXd::Index>(N));\\n            vals_r__ = context__.vals_r(\\\"x\\\");\\n            pos__ = 0;\\n            size_t x_i_vec_lim__ = N;\\n            for (size_t i_vec__ = 0; i_vec__ < x_i_vec_lim__; ++i_vec__) {\\n                x[i_vec__] = vals_r__[pos__++];\\n            }\\n            current_statement_begin__ = 6;\\n            validate_non_negative_index(\\\"y\\\", \\\"N\\\", N);\\n            context__.validate_dims(\\\"data initialization\\\", \\\"y\\\", \\\"vector_d\\\", context__.to_vec(N));\\n            validate_non_negative_index(\\\"y\\\", \\\"N\\\", N);\\n            y = vector_d(static_cast<Eigen::VectorXd::Index>(N));\\n            vals_r__ = context__.vals_r(\\\"y\\\");\\n            pos__ = 0;\\n            size_t y_i_vec_lim__ = N;\\n            for (size_t i_vec__ = 0; i_vec__ < y_i_vec_lim__; ++i_vec__) {\\n                y[i_vec__] = vals_r__[pos__++];\\n            }\\n\\n            // validate, data variables\\n            current_statement_begin__ = 4;\\n            check_greater_or_equal(function__,\\\"N\\\",N,1);\\n            current_statement_begin__ = 5;\\n            current_statement_begin__ = 6;\\n            // initialize data variables\\n\\n\\n            // validate transformed data\\n\\n            // validate, set parameter ranges\\n            num_params_r__ = 0U;\\n            param_ranges_i__.clear();\\n            current_statement_begin__ = 10;\\n            ++num_params_r__;\\n            current_statement_begin__ = 11;\\n            ++num_params_r__;\\n            current_statement_begin__ = 12;\\n            ++num_params_r__;\\n        } catch (const std::exception& e) {\\n            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());\\n            // Next line prevents compiler griping about no return\\n            throw std::runtime_error(\\\"*** IF YOU SEE THIS, PLEASE REPORT A BUG ***\\\");\\n        }\\n    }\\n\\n    ~model4fa476daf76_stan_model1() { }\\n\\n\\n    void transform_inits(const stan::io::var_context& context__,\\n                         std::vector<int>& params_i__,\\n                         std::vector<double>& params_r__,\\n                         std::ostream* pstream__) const {\\n        stan::io::writer<double> writer__(params_r__,params_i__);\\n        size_t pos__;\\n        (void) pos__; // dummy call to supress warning\\n        std::vector<double> vals_r__;\\n        std::vector<int> vals_i__;\\n\\n        if (!(context__.contains_r(\\\"alpha\\\")))\\n            throw std::runtime_error(\\\"variable alpha missing\\\");\\n        vals_r__ = context__.vals_r(\\\"alpha\\\");\\n        pos__ = 0U;\\n        context__.validate_dims(\\\"initialization\\\", \\\"alpha\\\", \\\"double\\\", context__.to_vec());\\n        double alpha(0);\\n        alpha = vals_r__[pos__++];\\n        try {\\n            writer__.scalar_unconstrain(alpha);\\n        } catch (const std::exception& e) { \\n            throw std::runtime_error(std::string(\\\"Error transforming variable alpha: \\\") + e.what());\\n        }\\n\\n        if (!(context__.contains_r(\\\"beta\\\")))\\n            throw std::runtime_error(\\\"variable beta missing\\\");\\n        vals_r__ = context__.vals_r(\\\"beta\\\");\\n        pos__ = 0U;\\n        context__.validate_dims(\\\"initialization\\\", \\\"beta\\\", \\\"double\\\", context__.to_vec());\\n        double beta(0);\\n        beta = vals_r__[pos__++];\\n        try {\\n            writer__.scalar_unconstrain(beta);\\n        } catch (const std::exception& e) { \\n            throw std::runtime_error(std::string(\\\"Error transforming variable beta: \\\") + e.what());\\n        }\\n\\n        if (!(context__.contains_r(\\\"sigma\\\")))\\n            throw std::runtime_error(\\\"variable sigma missing\\\");\\n        vals_r__ = context__.vals_r(\\\"sigma\\\");\\n        pos__ = 0U;\\n        context__.validate_dims(\\\"initialization\\\", \\\"sigma\\\", \\\"double\\\", context__.to_vec());\\n        double sigma(0);\\n        sigma = vals_r__[pos__++];\\n        try {\\n            writer__.scalar_lb_unconstrain(0,sigma);\\n        } catch (const std::exception& e) { \\n            throw std::runtime_error(std::string(\\\"Error transforming variable sigma: \\\") + e.what());\\n        }\\n\\n        params_r__ = writer__.data_r();\\n        params_i__ = writer__.data_i();\\n    }\\n\\n    void transform_inits(const stan::io::var_context& context,\\n                         Eigen::Matrix<double,Eigen::Dynamic,1>& params_r,\\n                         std::ostream* pstream__) const {\\n      std::vector<double> params_r_vec;\\n      std::vector<int> params_i_vec;\\n      transform_inits(context, params_i_vec, params_r_vec, pstream__);\\n      params_r.resize(params_r_vec.size());\\n      for (int i = 0; i < params_r.size(); ++i)\\n        params_r(i) = params_r_vec[i];\\n    }\\n\\n\\n    template <bool propto__, bool jacobian__, typename T__>\\n    T__ log_prob(vector<T__>& params_r__,\\n                 vector<int>& params_i__,\\n                 std::ostream* pstream__ = 0) const {\\n\\n        typedef T__ local_scalar_t__;\\n\\n        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());\\n        (void) DUMMY_VAR__;  // suppress unused var warning\\n\\n        T__ lp__(0.0);\\n        stan::math::accumulator<T__> lp_accum__;\\n\\n        try {\\n            // model parameters\\n            stan::io::reader<local_scalar_t__> in__(params_r__,params_i__);\\n\\n            local_scalar_t__ alpha;\\n            (void) alpha;  // dummy to suppress unused var warning\\n            if (jacobian__)\\n                alpha = in__.scalar_constrain(lp__);\\n            else\\n                alpha = in__.scalar_constrain();\\n\\n            local_scalar_t__ beta;\\n            (void) beta;  // dummy to suppress unused var warning\\n            if (jacobian__)\\n                beta = in__.scalar_constrain(lp__);\\n            else\\n                beta = in__.scalar_constrain();\\n\\n            local_scalar_t__ sigma;\\n            (void) sigma;  // dummy to suppress unused var warning\\n            if (jacobian__)\\n                sigma = in__.scalar_lb_constrain(0,lp__);\\n            else\\n                sigma = in__.scalar_lb_constrain(0);\\n\\n\\n            // transformed parameters\\n\\n\\n\\n            // validate transformed parameters\\n\\n            const char* function__ = \\\"validate transformed params\\\";\\n            (void) function__;  // dummy to suppress unused var warning\\n\\n            // model body\\n\\n            current_statement_begin__ = 16;\\n            lp_accum__.add(normal_log<propto__>(y, add(alpha,multiply(x,beta)), sigma));\\n\\n        } catch (const std::exception& e) {\\n            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());\\n            // Next line prevents compiler griping about no return\\n            throw std::runtime_error(\\\"*** IF YOU SEE THIS, PLEASE REPORT A BUG ***\\\");\\n        }\\n\\n        lp_accum__.add(lp__);\\n        return lp_accum__.sum();\\n\\n    } // log_prob()\\n\\n    template <bool propto, bool jacobian, typename T_>\\n    T_ log_prob(Eigen::Matrix<T_,Eigen::Dynamic,1>& params_r,\\n               std::ostream* pstream = 0) const {\\n      std::vector<T_> vec_params_r;\\n      vec_params_r.reserve(params_r.size());\\n      for (int i = 0; i < params_r.size(); ++i)\\n        vec_params_r.push_back(params_r(i));\\n      std::vector<int> vec_params_i;\\n      return log_prob<propto,jacobian,T_>(vec_params_r, vec_params_i, pstream);\\n    }\\n\\n\\n    void get_param_names(std::vector<std::string>& names__) const {\\n        names__.resize(0);\\n        names__.push_back(\\\"alpha\\\");\\n        names__.push_back(\\\"beta\\\");\\n        names__.push_back(\\\"sigma\\\");\\n    }\\n\\n\\n    void get_dims(std::vector<std::vector<size_t> >& dimss__) const {\\n        dimss__.resize(0);\\n        std::vector<size_t> dims__;\\n        dims__.resize(0);\\n        dimss__.push_back(dims__);\\n        dims__.resize(0);\\n        dimss__.push_back(dims__);\\n        dims__.resize(0);\\n        dimss__.push_back(dims__);\\n    }\\n\\n    template <typename RNG>\\n    void write_array(RNG& base_rng__,\\n                     std::vector<double>& params_r__,\\n                     std::vector<int>& params_i__,\\n                     std::vector<double>& vars__,\\n                     bool include_tparams__ = true,\\n                     bool include_gqs__ = true,\\n                     std::ostream* pstream__ = 0) const {\\n        typedef double local_scalar_t__;\\n\\n        vars__.resize(0);\\n        stan::io::reader<local_scalar_t__> in__(params_r__,params_i__);\\n        static const char* function__ = \\\"model4fa476daf76_stan_model1_namespace::write_array\\\";\\n        (void) function__;  // dummy to suppress unused var warning\\n        // read-transform, write parameters\\n        double alpha = in__.scalar_constrain();\\n        double beta = in__.scalar_constrain();\\n        double sigma = in__.scalar_lb_constrain(0);\\n        vars__.push_back(alpha);\\n        vars__.push_back(beta);\\n        vars__.push_back(sigma);\\n\\n        // declare and define transformed parameters\\n        double lp__ = 0.0;\\n        (void) lp__;  // dummy to suppress unused var warning\\n        stan::math::accumulator<double> lp_accum__;\\n\\n        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());\\n        (void) DUMMY_VAR__;  // suppress unused var warning\\n\\n        try {\\n\\n\\n\\n            // validate transformed parameters\\n\\n            // write transformed parameters\\n            if (include_tparams__) {\\n            }\\n            if (!include_gqs__) return;\\n            // declare and define generated quantities\\n\\n\\n\\n            // validate generated quantities\\n\\n            // write generated quantities\\n        } catch (const std::exception& e) {\\n            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());\\n            // Next line prevents compiler griping about no return\\n            throw std::runtime_error(\\\"*** IF YOU SEE THIS, PLEASE REPORT A BUG ***\\\");\\n        }\\n    }\\n\\n    template <typename RNG>\\n    void write_array(RNG& base_rng,\\n                     Eigen::Matrix<double,Eigen::Dynamic,1>& params_r,\\n                     Eigen::Matrix<double,Eigen::Dynamic,1>& vars,\\n                     bool include_tparams = true,\\n                     bool include_gqs = true,\\n                     std::ostream* pstream = 0) const {\\n      std::vector<double> params_r_vec(params_r.size());\\n      for (int i = 0; i < params_r.size(); ++i)\\n        params_r_vec[i] = params_r(i);\\n      std::vector<double> vars_vec;\\n      std::vector<int> params_i_vec;\\n      write_array(base_rng,params_r_vec,params_i_vec,vars_vec,include_tparams,include_gqs,pstream);\\n      vars.resize(vars_vec.size());\\n      for (int i = 0; i < vars.size(); ++i)\\n        vars(i) = vars_vec[i];\\n    }\\n\\n    static std::string model_name() {\\n        return \\\"model4fa476daf76_stan_model1\\\";\\n    }\\n\\n\\n    void constrained_param_names(std::vector<std::string>& param_names__,\\n                                 bool include_tparams__ = true,\\n                                 bool include_gqs__ = true) const {\\n        std::stringstream param_name_stream__;\\n        param_name_stream__.str(std::string());\\n        param_name_stream__ << \\\"alpha\\\";\\n        param_names__.push_back(param_name_stream__.str());\\n        param_name_stream__.str(std::string());\\n        param_name_stream__ << \\\"beta\\\";\\n        param_names__.push_back(param_name_stream__.str());\\n        param_name_stream__.str(std::string());\\n        param_name_stream__ << \\\"sigma\\\";\\n        param_names__.push_back(param_name_stream__.str());\\n\\n        if (!include_gqs__ && !include_tparams__) return;\\n\\n        if (include_tparams__) {\\n        }\\n\\n\\n        if (!include_gqs__) return;\\n    }\\n\\n\\n    void unconstrained_param_names(std::vector<std::string>& param_names__,\\n                                   bool include_tparams__ = true,\\n                                   bool include_gqs__ = true) const {\\n        std::stringstream param_name_stream__;\\n        param_name_stream__.str(std::string());\\n        param_name_stream__ << \\\"alpha\\\";\\n        param_names__.push_back(param_name_stream__.str());\\n        param_name_stream__.str(std::string());\\n        param_name_stream__ << \\\"beta\\\";\\n        param_names__.push_back(param_name_stream__.str());\\n        param_name_stream__.str(std::string());\\n        param_name_stream__ << \\\"sigma\\\";\\n        param_names__.push_back(param_name_stream__.str());\\n\\n        if (!include_gqs__ && !include_tparams__) return;\\n\\n        if (include_tparams__) {\\n        }\\n\\n\\n        if (!include_gqs__) return;\\n    }\\n\\n}; // model\\n\\n}\\n\\ntypedef model4fa476daf76_stan_model1_namespace::model4fa476daf76_stan_model1 stan_model;\\n\\n\"\n",
       "\n",
       "$model_name\n",
       "[1] \"stan_model1\"\n",
       "\n",
       "$model_code\n",
       "[1] \"// Stan model for simple linear regression\\n\\ndata {\\n int < lower = 1 > N; // Sample size is an integer with the lowest value of 1 (i.e. positive)\\n vector[N] x; // Predictor is a vector of the size of sample size\\n vector[N] y; // Outcome is a vector of a size of sample size\\n}\\n\\nparameters {\\n real alpha; // Intercept is an unconstrained continous value\\n real beta; // Slope (regression coefficients) is an unconstrained continous value\\n real < lower = 0 > sigma; // Error SD is an unconstrained positive continous valeu\\n}\\n\\nmodel {\\n y ~ normal(alpha + x * beta , sigma); //this seem to declare the model\\n}\\ngenerated quantities {\\n} // The posterior predictive distribution\"\n",
       "attr(,\"model_name2\")\n",
       "[1] \"stan_model1\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stanc(\"stan_model1.stan\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stan_model1 <- \"stan_model1.stan\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit <- stan(file = stan_model1, data = stan_data, warmup = 500, iter = 1000, chains = 4, cores = 2, thin = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inference for Stan model: stan_model1.\n",
       "4 chains, each with iter=1000; warmup=500; thin=1; \n",
       "post-warmup draws per chain=500, total post-warmup draws=2000.\n",
       "\n",
       "       mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat\n",
       "alpha  8.47    0.01 0.15  8.16  8.37  8.47  8.57  8.77   883    1\n",
       "beta  -0.08    0.00 0.01 -0.09 -0.08 -0.08 -0.07 -0.06   940    1\n",
       "sigma  0.46    0.00 0.05  0.37  0.42  0.45  0.49  0.58   860    1\n",
       "lp__  11.53    0.06 1.32  8.06 10.95 11.85 12.52 13.03   566    1\n",
       "\n",
       "Samples were drawn using NUTS(diag_e) at Mon Sep 23 02:42:14 2019.\n",
       "For each parameter, n_eff is a crude measure of effective sample size,\n",
       "and Rhat is the potential scale reduction factor on split chains (at \n",
       "convergence, Rhat=1)."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 4\n",
      " $ alpha: num [1:2000(1d)] 8.63 8.41 8.63 8.49 8.7 ...\n",
      "  ..- attr(*, \"dimnames\")=List of 1\n",
      "  .. ..$ iterations: NULL\n",
      " $ beta : num [1:2000(1d)] -0.0765 -0.0767 -0.0846 -0.0688 -0.0863 ...\n",
      "  ..- attr(*, \"dimnames\")=List of 1\n",
      "  .. ..$ iterations: NULL\n",
      " $ sigma: num [1:2000(1d)] 0.487 0.452 0.496 0.545 0.468 ...\n",
      "  ..- attr(*, \"dimnames\")=List of 1\n",
      "  .. ..$ iterations: NULL\n",
      " $ lp__ : num [1:2000(1d)] 10.3 12.72 11.72 8.48 11.56 ...\n",
      "  ..- attr(*, \"dimnames\")=List of 1\n",
      "  .. ..$ iterations: NULL\n"
     ]
    }
   ],
   "source": [
    "posterior <- extract(fit)\n",
    "str(posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAABNTU1oaGh8fHyM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\nYTaxfLkAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(y ~ x, pch = 20)\n",
    "\n",
    "abline(lm1, col = 2, lty = 2, lw = 3)\n",
    "abline( mean(posterior$alpha), mean(posterior$beta), col = 6, lw = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAM1BMVEUAAABNTU1oaGh8fHyM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\nKIBIAAr8D/FNZA1JjaERAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(y ~ x, pch = 20)\n",
    "\n",
    "abline(lm1, col = 2, lty = 2, lw = 3)\n",
    "abline( mean(posterior$alpha), mean(posterior$beta), col = 6, lw = 2)\n",
    "for (i in 1:500) {\n",
    " abline(posterior$alpha[i], posterior$beta[i], col = \"gray\", lty = 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAABNTU1oaGh8fHyM\njIyampqnp6eysrK9vb2+vr7Hx8fQ0NDZ2dnh4eHp6enw8PD/AP////+0o53LAAAACXBIWXMA\nABJ0AAASdAHeZh94AAAgAElEQVR4nO2di0LjOrJFHQgBNQcy+v+fHZJYUslPyS7bsr3WvQfC\noyPRnTVbLpVMZQFgNtXWEwA4AogEoAAiASiASAAKIBKAAogEoAAiASiASAAKIBKAAogEoAAi\nASiASAAKIBKAAogEoAAiASiASAAKIBKAAogEoAAiASiASAAKIBKAAogEoAAiASiASAAKIBKA\nAogEoAAiASiASAAKIBKAAogEoAAiASiASAAKIBKAAogEoAAiASiASAAKIBKAAogEoAAiASiA\nSAAKIBKAAogEoAAiASiASAAKIBKAAogEoAAiASiASAAKIBKAAogEoAAiASiASAAKIBKAAogE\noAAiASiASAAKIBKAAogEoAAiASiASAAKIBKAAogEoAAiASiASAAKIBKAAogEoAAiASiASAAK\nIBKAAogEoAAiASiASAAKIBKAAogEoAAiASiASAAKIBKAAogEoAAiASiASAAKIBKAAogEoAAi\nASiASAAKIBKAAogEoAAiASiASAAKIBKAAogEoAAiASiASAAKIBKAAogEoAAiASiASAAKIBKA\nAiuIZFL43//+l/R9T6r6XVW9Pnq8f/33wPg3ANPIf5WXItLDpHSV3HO+ntyaxyjPx68BX6Mu\n/5PBQdmzSHkmOZke1nSY9FJp+R8NjsmuRcpc3jVMMpFJFpNgBjsXKc+k+nlfJtUPwooOk2A6\nexdp0oUSJoE2uxcp+0IJk2AB9i9S9oVSLdDznXlZhEkwkyOINMskg0mgwCFEmrK8s2F5h0kw\nm2OIlGOSf/KnSdY0yuCYBFMoU6Qq26SJyztMAh3KFMksG0otkwwmwTwKFUmswJYzyWISaFGs\nSBNMyl7e2bChFJUcMAlyKVekiaGU+SeCtJgEMyhTpGqGSYkqNY9V+A+eE8AkyKNMkczkUJpS\ncqjfWEyCyZQpUmXMmss7TIK5FCpSHUoTCg5ZJrmCHSbBTMoUqW7JFq/2TJMyj/u5A3/+nZsE\nJkEahYpk/EnwKbmUW3IQXXfunbV7MGnKLTdgEcoUqXLRMCOUcr5d9q/uyKRpN6+BJShTJLe+\nMnNCKc8k79N+TJp6GyhYgEJFCvcpmVZwSFve2ebDfZmESAVRrEhhp9Ta5qt+KZNcJ7gJxbvi\nTdp6DvCiXJFUQintG6184BaT+zBp6xlATckihVf3hFMVtUmZm7N7MwlKoXCRomLaMibFy7to\nbxaTIJUyRaoaL/VpB5RqlfJMCka5iyVMgnEKFakVSouZ1JV2/pyS9fcIxyQYpFiRWtdJU1XK\nWN4JZzEJsihTpLpttPVaX9akaI1nw4LSYhKMUaZIVX2Z306NpfrBm2P5I1GYBCkUKpIPJdt8\nsa9nksEkSKZMkepjFLZ5G5SuD1NNGlMpflrrt5JcGRyTYIAyRarCS1cplLJMMtIkg0kwTqEi\ndYWSuEiaqNLYt0TP7UwKW7OYBL0UK5LtDaV4dzZreZdkUvjANop3mAR9lClSuGuC69IJrQbT\nQylxeSer4KJ4ZzEJ+ilTJFf+Dm86Q6m5j7qcSRaTYJBVRfrv8/o8i3a9/Tc6hPF5NBBK2bE0\nYlJHv5Av3mESDLCiSPe3KvA++K0uhfpDydju132CSUnVu+gizA2OSdDHiiLdqsu/n+ej3+9L\ndRscwniVtEMJk2AJVhTpUv34xz/VZWQIoZJ70Lwqmh5KKSZFHzqpqd1BNyuKFJ2LHj4k7cvf\n9cV+/eAvqUQ5Or/YkGVS1MKKSTBMmYnkur/d2/rB37VVhz35oTS+vGt0U3ifMQm6Wfca6fv3\n+SjnGsn6Wyj8ffZRpohDqeOFP9+k9rNZdyzJXyphEkjWLH+/i6rd231kCBlKryKDfeTR35Iw\nCiXb/+IfUynl28LTh1yqC+GYBIJ195Fuz32ky/VzfB8pNNrZ+r2xrzxqNO4sa1LklCjeYRJE\nFNrZ8HwbhdLzxfvKo8aektcpT6W8CyVhksUkaFGmSM6dZiiFLzZDKTYpSakMk3yREJOgm0JF\nCjEUfSRqEN2hlK5RrVKiSf5DTIJOthJpZB9JuPN6G33oXsMikFxxWnt5h0mQRDkiVZKOUGqY\nZQdDaTGTQskBk0BQ5tKuvq/d6wPX2OBesaHRwZpKWBSFkt7yLkjUMIn9JAiUK1JCKIlGB69T\n66W/pEkGk+BFySKJ0nd3KL0aHcQr3bfx5JD5G2dDU7rruMAkWFWk34/q8mnt11t1GWwQEkOY\n3lAyz5JEpRFKs0oOmAQP1jzYd3kkyNdnwsE+MUQrlIRKfxZV9Sf9i9ymydNSaYJJBpPAsWrT\n6l8O3S7Vx93ebyNNq+KxaYRS2K19BJJxzaRxWGASrMuqxyief7p6tquOHuwT9IaSa8luqNM0\naYHlXei6e32ESWdn9YN99QbS+ME+gWmFktuXdVcrjVCalkmYBJPZIJEeb+85iWTboRQaWo1R\nDKW1TeKXKR+GDa6Rbvf6cdYQvaHkP2iGUjbTTHJF8QkmvXo44AgUX7Xz9IeSq0AEfab1CyUv\n71wKvdJwskmuGwoOQOH7SBFxKEUdrPVLuQ6lKXGUZVIQSjQl2VyTEOlAlN3Z0CAKJV9ncAu7\nuPJtzaRgyjbJzDRp8t8RFMWuRGqHkpWhZFcKpY5OimBSlkp4dBh2JtJwKBl/wRQVHPKkylve\nxeXC51QW/9uBAtmbSIOhVG84hZPhk0zKW97ZSFo/EzgZ+xOpN5TqT3aG0lImVZFJtAudlx2K\n1BVKJnw2DqVpW0vpF0qVf27rvMKkM7JLkfxLNQikHErpJrkk8l6J6cF52KlIU0LJ5IZSlkn1\nG0w6KXsVaTiUrE4opX3jy6TnMK+FnpgHnIX9ijQcSq59x5jJoZS8vBNdd5h0VnYsUlcoGflZ\nMzOUskwSNXdMOiG7FqkVSq+b7DdDyc4JpSSTRMkBk87JvkVqlBfqe6EkhlKKT5NNErOAM7B3\nkWQoVc/fRCb2aK2oA8hQUt1R8j0NkUaYdDJ2L5IIpeppkpWNQ/4aZnIoJbfe2bD3i0nn4wAi\nhfhxK7v66qj+rNwyXWZ5J02ymHRKjiCSDCXRwypqDiKUGvJYlVASxTtpksGk03AMkaLynX4o\npZvkSw/hyknprwTK5iAiNbuD6odJoZQCJsEwhxHptZKyMpRsFEqicCffJnqVU7yLnhKTzsFx\nRBoPpXAJY/KTaXR51zTJF/Ew6QwcSaSUUGrEkeqOkjTIhlY/g0kn4FAipYdSsChPpQSPWiZZ\nTDoBBxOpM5TCCzmSpxFKHfu1k0xqZxImnYCjidQVSjaEUvNuXZV/3SeRWAePmxww6QwcT6Sc\nUJKvfiWTTLdJBpOOzQFF8io1Qsl/VWwo+Rd5slSpJnUsHOHAHFKk7lAyUShFNxjKWd9lXSiJ\nCyZMOjTHFKk7lEwzlOJXfuP9kEnpyzuLSefgqCLFodT4nDg71JEho6SbJMIOk47NYUWKQskM\nhlJo50k0KflCKZhkjdwbhsNxYJFmhNL85Z0zSJhEt9CRObJInaFkdUIJkyDi2CKlhVKnPCmh\nNG5Ss28Ck47KwUXKD6Uer6abFJUc5CzgSBxeJL+BFIdS+GpnLTzVpEGVOk2ieHdMji+S72ro\nDaWok8ckrOrmmEQZ/JicQaTOULJxKGUqJFTKNYlMOiSnECk1lOykUBr/pg6TUOlgnESk/FDS\nbXOoO4WCSVTvDsZZRMoPpVSyTPLFO0w6GOcRqSeU5J5Ss88hXaUUkwwmHZgTiWRdwWw8lDJJ\nCqXmhhImHYpTieT7RodDaSGTTNskVDoM5xLJGhlK4pP+kZmuUrJJoaAxFkrVCn/XoMLJRIpC\nyXSpNCOUkkySO79jJlUVJu2F04nUF0qipbWpUppVmQdnE5pYqwqTdsP5ROoOJTM/lKaa1KsS\nIu2IM4qUEUqiLpCmUrJJ4WBFfyjh0X44pUghjPRDSdmkhf8eQIuTiuTDKDWUEq3KXt6NmAR7\n4awi9YaSf+j+L48Uk2x0pAKTDsF5ReoJJXki3YVHbiglfJdsBHeTgB1zYpHSQin/Sin5CLrU\nilDaOacWqTeUjPuyeOVnmZR23C98/BoX9su5ReoLJTsvlNIulDDpSJxdJN8KnhpKijtKr6d3\nxUHLhdKeWV+kr7equn4vOkQeJvwnLo+aoSSzJM2klJMVMvLcXGCPrCjSa3fx/dX4cltkiGl0\nhZKJQmkpkwwmHYW1RbpVt7u1v7fqa4khpiJDSXxutkqDDpn6QikcrXBTgf2xtkiX6v54fK/e\nlhhiMiKUZM3BLm0SZfCjsLZIrntsuItsgxazJUJpZHkX9mRD852l5LBP1hbpw4l0WWKIOaSF\nUl4hPN8kQmmnrCrS9fPru/r39/B+G642bNP0LLZmk0JJyjCg0rhvmLR/VhXJn1Srqst9iSFm\nIrZm41Ay9cM4lBQvlDBp76y5j/Tz8/V1vT5LDrdBj7YSqTeU4vVd3u5s2vKuZZKKSpxnWo3T\ndzY06AwlOyuUUkwKm77OJI1Q4oTteiBSk45QMvNDafDrtUv+vdLyjns+rAgitRgJJfd5TZPc\nE1m/R+sGnQMirchWIhW3jyTpDSW/vksUSJqUctyvadJMlfBoPcoRqZJoDDGDvlCyUShpmxSW\njf6g7myT5v15SIalXTeLhFKKSUbVJFgLROrBadMOJaeSCKXUHaWxLaVGDcOPCcWDSL2413Ez\nlOzUUBo2qXHsqb5aWtckloKTWbOz4fLf0kPoIkPJf85/wYYd1ByVhkxyb0MlXIy2AgVcne6W\ndVuErsMNDbOH0CaEklELpXyT1gqlIuo8e2VVkb4v1Uhv0Mwh1EkMpXSXBpd3kUnuqf2Qi4NI\nM1j3GMX9WlUfI/drmDPEAnSF0uttLZTJzqSkHaXgVhhyafBoOmufR/q5PlZ4Xz+FNq120BFK\nUTdc5mVSeptD/WDNCyU8mszqNz+xP7fL6BKirH9P90ruDaVMmRIulOQn2FHaA+uL9MfP1/Vt\nRyL55VVOKA2ZlbC8E38ck/bAJiItNsRipIRSBnkm0eWwAxApjYFQmqpS0vf5asZreCgVOhui\ncQcG7g0lG5mU6lO/SeFUkjBp7b1ZyASR5LCDNZCRUDKZRYfMI+gs78oGkcSoY9VE3VDKOKOE\nScWDSGLU0bJ82ITtC6Uck5Lr4BaTigeR5LDjO/vuxdwRSkYs7/RCyV0xhTvscaFUIogUjTs+\ncFcohfddeaJmEqFUMIiUjQgl95muUEqk1yRfvMOkPYBI+Yh21VYouVbwrOVdyrdhUtkg0hT6\nQ+n1KROMSjIpRSWnESYVCSJNYjCUjPXLMlWTKDkUDCJNxB/s6wilV3YoLu+sf8fyrlAQaSp+\nA8kMhRIXSicBkabTYVL0wIiqW4JJqRdKmFQiiDQDfyjJtELJuk6H1K6hxFuxNvqFUKkUEGkW\n/cu7zlAa9CnHJBMkhiJApHm0Q8m0QmnMIGFSQpuDrxViUkkg0lzSQsmmqDRkUuvPY1JRINJs\nBkLJCIO0lnev57BcKJUFIikwWghP36BN3FHyPkWjwXYgkgbtPaVWKMnd2SGlxpZ3DZPi5R33\npdsMRNLB+9MOJdte3g0x40KJO6VuByIpIUIp/oyVtYa5y7v2nxcmce/uDUEkNXpDKd7/SVAq\n4653vgH97yEibQgi6TEUSjbtCimYNKJS2yRrWNptCCJp0h9KNrXYMG6SjR9aUXLAo81AJFU6\nQim8kyGSolKySSYqOcAWIJIyrVCSFeogQFIojevmdqjYm90aRNImCBSHkpGhlGhS6i9SkhdK\nsAmIpI9WKI2ZJMqBiSZxDbUYiLQAvaFUfzHVpNQ6uNcpDNUJVb3lQKRF6Akl0UmUbNLgL60Q\nvbB2tOTAPtOCINIy9ISS7BSPL5ryTRJC2dikHpUQaUEQaSkUQynXpL5QwqPlQKTF6Asl90Vj\nZD/rDJNipcJIbfBoMRBpQaKjFK8HNooqo7S88yb5oSiDrwwiLUl3KJnc5V3eTY3Zm90CRFqW\nZvtqtLzTrIM7mUaXd7AIiLQwrVASyzuZJXomWUzaAERanM5QEof+kk3KCKV45F4oPqiBSMvT\nGUrxjlKCSulnlJJLDpTD9UCkNRgIpVaLwqBK2SYNqcQGrSKItArtM7MmPvSnY5I3Kml5h0iK\nINJKdIVSw6RxsurgaSYt9fOeDURai65QEpcyXoHZJrk+viSTFvtxzwYirUd/KCU1OHiV0k1i\nb3Y1EGlF2qEkl3fpJqXdrMsmhRLogEir0rW8E1+pNRhWKtmknB0lmAkirUtHKEUdDykmjS3v\nrO86wqTVQKS1aYeSaS7vUjZnMaksEGl1BkLp9dkEkn+5XxiGksOiINIGdISS+EKtgcaFkiWU\n1gKRtqCz0cG/T8qkweWdX9dh0log0jYMhtJ8k0xsErePXBxE2oj+UHp9IJJlwKSxLtawo9QY\nFZRBpM2Yv7wbMSkU71jeLQ4ibUdXo4N/n2TSyPLOGkoOa7GqSP99Xp+d+9fbf0sNsS+CSXGJ\nOqsOPvRlK0ziQmlJVhTp/lYF3hcZYnc0Q2mSSWnLO8uF0pKsKNKtuvz7eT76/b5UtyWG2CGt\nUHIf2vkmWfGfEUcJCSV9VhTpUv34xz/VZYkh9shQKMVODKg0nEk0sS7PiiJFp8iGj5SdSaRW\nKHUv70ZMSvyVZFwoLQWJVAA9oaRZB/cPMWkZ1r1G+v59PuIaqclAKCWZlLC8a5mESpqsWf5+\nF1W7t/siQ+wWE6tkZOlhtkk2kokLpSVYdx/p9txHulw/2Udq0TCp+1c4D5vUq5KN3mDSAtDZ\nUAxxKBkjQsk7NKvkEJ6HCyV1EKkgekLJqvWDt01CJSUQqSQaoWTjC6XRezmkXSi5BzY8Ocxm\nK5HYR+qmaVIo4hm/sBvQKf1CyWCSKuWIVEk0htgn4qTfq9/09ZH/jBBqoklRI6vFJB1Y2hWH\nCCUTQqn+jGtAHVQpOZOi9j6YAyKVhzjhZ/zNWMP2kpEmZIaSN8q6cJMDwnQQqURkKPlW07C8\nm2GSWCCyvNNkzabVy8g27PwhDoMMJd/W401KUWncJC6UNFm1+7u6DjYGzR/iQHSFkr9QmmOS\nkZkklncb/ZxHYVWRHr2qSSohkjQpWGQaoTRoUsrvyeRCSYt1zyPdr1X18b3cEIdC7s6GPLJ1\nEULBpPgSLCWUzrwvMcLaB/t+Hm2r16+f4WDi3+tJI5RkMI2blHIDyUyTzr3DN8z6J2R/bpfR\nPVf+uV50hVLW8m5EIldvMEkXSmffKx9kk6PmP1/XN0RKYlYoDS7v8k1CpAG2umfDMkMckM5Q\nss6kEZUSSw5ieTdYcsCjfhCpeDoK4c6kmcu7l0lWhJ0dDiU86oXOhvLpCCX/3iaE0ngmZVwo\nQTeItAcGQsnOWt7FF0oWkyaDSLtAHK6wURi5Vdlck9ibnQki7YR2+U5k03AmpV0oOaOi0SAV\nRNoLUSiZEErOpMmh5ExieTcHRNoPIpSsaSzvxjMpxSRvKSblgkg7ohFKvtZgx2+LktgPjklT\nQaRd0Qolf6E06w5DxjRyzY0BqSDSvpgRSskXSoTSBBBpb7RDyWqalLW8o9PBg0i7oxVKYXk3\nRoJJVpTwUtrBl/959wEi7RBhknvdh9MVCiaFk0qDF0p0gwsQaY/4DgS/pBNajZk08mvQbfKF\nEiIJEGmfNEPJXyipmCR6HcZMWuWn3QGItFO6Q8mm1RxGvsMtGENjXw945EGk3eJ6eaLWu/F2\noZySQ9AKRkCk/eKuYXwoBZNGMylleWfERtXGP2r5INKSLL30qTsQgj6+aq1ikvUfYNIYiLQg\ny1+Mx6HUMGmkH3xAI+OKF26Bh0ljINJyrFIeliZFdfDxC6Wx3zgb9qgsJo2BSMuxzj6LK1HH\nEs2/UAobvD7rlv5R9gwiLchK+yz+VJILJRN2lKYu74JBvipIKA2BSEuy0j5LK5TMiELpJkU+\nYlI/iHQIpEnOIL8gGzQpIZR8Mx8m9YNIx8AV1oy4PooaxKeaZGxYK3Kh1A8iHYVwlsLa6MU/\nXHoYN8mdIBRNQ9ACkQ5DZyj5c7STTRKt4O4poQ0i7YmR4oU0yff4WGlBj0nDbQ5ip9dv1kID\nRNoRo+V0lxfu5e/L1rNMcmULi0n9INJ+SNng9UeTZPlutGNofG9WPBUqdYFI+yGpU6IZSs1j\nFlNNivZmMakFIu2ItE4JZ5KVQWKjckGnSSMXSjY8cIkHAUTaE2mdEvWrvLUm63EoxSRxYMNg\nUheIdEScSlEo9aZRUGnIpPjsEyo1QKRDIkPJezC3zcE9I8u7DhDpoNSv8nDrhYTzfsknK6xv\nOYcaRDoqzqSgjp25vBNPYTCpASIdF+Pe+R3VpOXdoEmyZwKVBIh0YEQouR6fYY1M5sFZi0kO\nRDo0MpREu8PQbYZSzygZXxTf8OcrB0Q6NjKUos6hucs7f1KDUHqCSAfHhFDKWd4Nm2Saz4dK\niHR0TBRKRizvBk1KW965+0VgEiIdHxlKonFonknyCLpFJUQ6AzKUXOv2iCbpyzuDSQ8Q6QwY\n2x1KIyaNh5I1vhxozq0SIp0C/yqXJo0UHdJ+d3Oo353bJEQ6CS6UwiZSWJkNqDSSScYIj06t\nEiKdBX9POqnOyAJvvHhnwm86czqdE0Q6DcbauOZgzfzlncskX8A7aygh0nkIgdGwYJZJVnbd\n+XL46UCkMxGFkgyTYZXGIkl23Z01lBDpVITAcB6pmeRbwV8fnw1EOhfucGswabTzLuNCyYqE\n2/Kn3ABEOhniDFH9+jejoZRmkg0mnbAQjkhnw8hQcr/4KKHmMGqSuDPlCfeUEOl8hFAyIpQ0\nTfJND+dhfZG+3qrq+r3oEDBMONhq/Ks+dDz0mjReB69TyIQ76m35Y67KiiK9bhP6/rqD9W2R\nISCNcLC1kUjD/UIZdXBztpbwtUW6Vbe7tb+36muJISAR0wqlKFZ6VRrVyPhn9qXwDX/MFVlb\npEt1fzy+V29LDAHJiFCKLpKsUCI/lIJJZzvxt7ZI7jbww7eDR6TlMf5tnEdDpfC0g7OnDKW1\nRfpwIl2WGAIy8CVwK2JIhFKfShkm+f3ZLX/OdVhVpOvn13f17+/h/TZcbUCkNfDHKprlhqGq\nQ1LJITYpnOA4MKuK5H/lXFVd7ksMAXm0Qsn6HdqhTEpRyT+xP16x6U+6OGvuI/38fH1dr8+S\nw23QI0RaC38rByuiSKP1LgolE66YDgudDefGmWQyTBpa3kVHnawvZhzfJEQ6OcaHkjuXZ+Uv\nVco2KeJvHe/WjUc/84dIp8eHUrjtgouWoZJDkkqPK+Jw4XXkXaWtRGIfqRzca9sY1yQ3VgRP\nNKl6/GdD1JkDq1SOSJVEYwhIJTLJOzR+SGk8kYw/tCFD6YgqsbSDYJJdwqRw7eVaWY94vmKm\nSG+fv2pT6RkCVsCEUIrqbmMmpasUWmSPGUozRfpbhS3hEiKtTgil0A+eULwbu6lxZFIUSgdT\naaZI938f6S7db48Gu8+3qnr/pz4rmIlY3kkRlJZ3Jtx2xRyy10HhGum/hxoJLv1eqsreL69q\nwrv2rGAujQsl6w1o5UtsUmoouQulcNuII6mkU2z4eegxeFTPPhq/r/e/Nx9/xv1+0LRaHqYZ\nSk1zZphUrxTDrcDEkaVDoCLS93tCyvxdT93rN4+DfRyjKJD28i4s7nr3lpIzyYRM8qF0mALe\nfJHun39x9PZ9/7PpOvznXidkxQeaswINpElW/P9QJqX8zgr/VvYkHSqU5or036PYcPt5fWH4\nyT6qv2/7rJ7fex+OL0TaClm8s5ECPlI6TUpd3nWG0hFUmruP9BdGX+5IxPByzf5Ulz/jrpc/\nk77fqsEbciHSZogdpZYDvaE0bpKN3oqxzEFUmruPNHaHOsn3JfQAfWrPCrRYY3nnR3Dj7V6l\nuftIeX/038fbw6LrWK0ckbakUXKwzVCaZZJrQfJDOIl2bhK9dtCi0eXg+8J17tXVDCVziFBC\nJGgTAiOpfTXLJB9KfqwQSjtWCZGgC2GSbzQdbWedZpIIpR2rhEjQSeOMUig9jCzvhk1yQvnL\nLzeGv2zaq0qIBN3I1rtQpG6Xw5smZYSS6EmKfinn+j/sfBAJemhU1nx33CCpJvlaoBtD9LTu\nsoCHSNBLvN0jlncjKo3I1m2Sv9WQ3WUoIRL00zJpVCOTcXC2cVRWnKPdoUqIBAO0a9Qqy7uX\nR4OhtDeVEAmGiEoOYnk3qlKiSc0rJRvtMK38w84BkWAQ032hNOJSgklR+c6PZl3dwX+4ExAJ\nRmiYNFIADyZlLe8avXf7CyVEgjHiV3VzK2iuSZ2hFJu1BxAJRmmaJNtPB1VKMKk7lORNJPeh\nEiLBOHElzbhmofFQSjPJ397VDWfjyvgeVEIkSCG6/A8OzF7e+f5V9z4aJQxfvEqIBEk0lndx\no88Mk5xOtmMTKVJp3R83G0SCNLpNUqiDP5/Fn9fYayghEiTSTAvrL21GTEoNpa7Oht2ohEiQ\nTNy803/LyGkmhVCKmsClPgWrhEiQTodJag1DxovZGMfsQiVEggzi3h11k1qV8I5TFYWahEiQ\nQ/MVHs6hj5g0NZTiYZuPywGRII/WK1zNJH9Yo/7ADSDe2fYHhYBIkEnTJNEvN6zSqEnGm+Sa\nV6OB5ByKUwmRIJdGycGlh5JJonzXuESK5ClNJUSCbBolh3STso6gj4RSYSohEuRjmss7m7K8\ny/st6HEoNQaOhi8CRIIpDJg04FOOSeE53QhyxDBuISASTKLHpJFuh3yTgko2DCWmUYpKiATT\n6DJp8H7GzqRUlZxPbhBTtEqIBBNp7PAYm7S8SzfJJIZSGSohEkymYZIMpYHKQ97BWRuFkh/Z\ndExkUxAJpjPZpNRQMqHUEJx6faaw9R0iwQw6L5ScABomyaJdSCb/KTGTjVVCJJhDc8dUnpzV\nqN69nssKi/pCaWOVEAnmsbxJtj+UylEJkWAmrQsl4/8bNqlHJdv12A8xaNKGKiESzKXLpA4p\nkk3qVqIMlWMAABWcSURBVMqKUDIDKq3zM7dAJJhN3MUzIlCkUsJ3dYSSiUOpiPUdIoECXSaN\ny9RvkrexM5RsHErNFNpEJUQCDVomJZG3o5QcSluohEigQv0id9dLPlaGsyn9d1a83r2evB7P\niME3VwmRQIeo5JBYcDCjF0qtP+wHMdIe01rfrV11QCRQIio5yAucWSY1tIpCyRQUSogEavSZ\nNEzuhVK0votDaUOVEAn06DBJNN9NNck2PwyjNEKpvb5bTSVEAkVik0SdQW9593o6mxhKq6mE\nSKBJXQfwcTHUBB6bNHl51wylbVRCJNDl1QzXs7xTMkmoauM2IdOxvlulgIdIoIzIpKZJQ0bN\nMKmp0hahhEigTceFUkrbUPLe7Msb79DrrYnGX18lRAJ1fBePjUsOI0u88eWdbTx2I9iO9d3K\nKiESLEDTpPEbOWSYlBZKj/+q6IW0qEqIBEsgi3feJDtaw0s7o+QyTspqY1FeX6xik5asOiAS\nLIIo3vnOuPFMSjTJv49DKVbpL48eKsWzWkwlRIJleBWihUkmmDRgU97ybjiU/gLJNF9KS6m0\nqkj/fV6rB9fbf0sNAeXQMMlVwWeXHPzybjSUHia1d5UWUWlFke5vVeB9kSGgKFqZlGRS6vIu\n8UqpQ5wlVFpRpFt1+ffzfPT7faluSwwBZeFCY1mThq+U3Jt4YuoqrSjSpfrxj3+qyxJDQGGE\nkkNUZ0gwKVWl1wfZoaRewFtRpKiAUg0+CyIdhbjk0Nia7fcpwyRfDfTj2a5QWnp9RyLBsrRM\nirJkSKUUk8LjkVBaen237jXS9+/zEddIZ6JhUv3CH+0Jz1ze2QmhpKnSmuXvd1G1e7svMgQU\nSNMkq2tSeNwMpbj7blmV1t1Huj33kS7XT/aRzkS9oLOyycGZNGRT6skK3zbkto16uu86SwxK\nJtHZACvgV17SJKNmUk31/P96wOfb9UIJkWANXolhZbvQmEW1Sekq1R6NhdIyKiESrIK/UArt\nQq+XubJJ1eiVUuf6brZKW4nEPtLZqC+LIpPcNq3W8q4ybrOqHtHa+M6RvaE0W6VyRKokGkNA\nYbRNMtomGbcDLPaO6jVlPYelVGJpB6sR5ZBokxuRI2t5Z0dDqXd9N6uAh0iwHrJ45xpavUmz\nGoaESeIZbei1Syk6zAklRIIVMabLJPGoX6Vkk/yW1Wgoaaq0pkj326PB7vOtqt7/LTQElM6Q\nSQNktTn0hVKz6NC9vpum0ooi/V6qyt4vHOw7N9Kk8OLXvVByoWTiUEorOkxTaUWRPqrr/e/N\nx++fUx80rZ4W9zr3NqWZNOVWrCZSydiuUFKqOqx6Hulev/lb5XGM4ryYWqPYJI2TFQ2VbFDJ\nv2mFktL6bu2DfZdKfKA+BOyDLpPseChNudO+cRW73FDKVGnVpd2PtZ+v03334YskRDo4PZmU\nULwbNslG7/tCychpyPetOaazokg/1eX2Y6+XP5O+36rvJYaAvRCbFC/v1NocXIdDM5RsK5S6\nr4pyVFqz/P19CT1An8sMAXuh06SEc+jJJvWHkk0OpQyV1t2Q/ffxvLfd9fN3sSFgJ7hWHutf\n2sGkIZKXd+Ej9/Rh1M5Q6lYp8cehswG24nkj1FAJVzOprZQNRYeBUJq1vkMk2Ir6+JBtmDRO\n/vKuO5SCSu79dJUQCbaiapmUdKwix6QolGwzlGxHKE1VCZFgM173KjF+eyfLpNmhZG1XKPVc\nFI2qhEiwHVXlWu6s21BayCRjQih5ba1ND6WxqgMiwba8HIpMGu9xMNl3GBKhZEdDacL6DpFg\nY2aYpBRK7SzKX98hEmzNKxwaG0qPz1T6JrnlXBRKHRdIfeu7XpUQCTanadLrBW/MmEnZyztv\nkrgU8zOIH+SqhEiwPS2T7MImRXtX7hM2ftBXXuhWCZGgBOp8aJk0Rt7JCncTMDsrlDoNQyQo\ngqgJTpo00jSUalL0JK8R/aAmV6WOTyMSlIHLB3mswro7G4+olGJSMEqEko1Cac76DpGgEPyF\n0uImGW9SuJ9kmEP8oH99F38ekaAUuk0ySSZNVimMVk/CzyaaV998PYgExRBMEpWGBUoOuaHU\n2x4kPo9IUA4mdPLUJtnRaoNXKUOhViiZKJS8SmJifRN2jxAJCsLnUagCKJvkLAo1BuOLDq07\nOJh0lRAJSsKYPpN0L5Ss6VzfDYRS//ru+QVEgrJomRS/8BVMkss7jVB6fgGRoDBcPvjrJP0j\n6O5ZO0PJT8M9kFPrnTMiQWnUS7lpJmWEkm2HkhHLO6+NSVjfJd9tSIBIsCxhM8mG4l1S7112\n610jlGwUSq11nu0PJRIJyqPLJJtk0rTlnQ8lkxJKnSohEhRI/YKOmhzSMmlCw5AbKwhsBkOJ\n7m/YDaaWaZpJySrZ/lDyM0kLJUSCInG7RzbWJ2VzNv9CaSSUmm14tkMlRIJC6Sve6bc5jIVS\nqw1PfM6BSFAqxm2QrmFSK5S613dyepFKiATFYqxtmJRM1vJOiBNCySaEkvgAkaBcOk1KiqRc\nk9qhJD56zaUjlMQHiAQFM8OkvOVdO5RsO5SMfGfjDxAJSqbXJOULJRFKpjeUWrd2eH7w+giR\noGhMuGSxzVd+gklTlnculMKYYTYdofT6bkSCsql3ZNstrHZcpjyToie0NjRXdIVSc32HSFA4\nxkw3afLyLoSS6Q6l5voOkaB4BkwaZeLB2dodN2pXg1DH+i4PRIKV8Sb5i5bWq17XpOFQ6io6\nkEiwA1oXSjYvlNJNangVQskMhxIiwR6ITbIrmCQL4T4K4wlZEUqIBLtgrkkTbiDp2+1ERU9M\nKA4lRIJ90LO6U2kY6nmKKJT613fPt4gEO8G17ojiXV0TSDApcXlnW4+GQsmKUEIk2Auta/+6\nfyjFo2m/Bd1p+hzdDoYSIsF+cMu7DpPGdcpe3mWFEiLBjugyySiZ1OdWcijlgkiwGT0mLbS8\n6wklJ5abE9dIsDsaJvkNnmSTcu4w1BNKXes7RIJ94Yp3kUk5JYf5odS1vkMk2BneJDMlk6Y3\nDLnLod5QygWRYFNqk0IMLWdSZeQzD4USiQS7o8ekVPKXd8YnUBRKsuiASLA/TLPkEKrg6iZZ\n8bYRSnJ9h0iwR9rFu2QzapUyTTIdoWSFSYgEu6S9oZTl0+TiXQil5yy8SogE++T1YjZGmJTR\nwzpheRd6KELXXwil9UX6equq6/eiQ8AZaJiUm0rTd5SCSs9pvD6/okjV8w++V09uiwwBZyI2\nKewrLdUP3htKtVy5zBLpVt3u1v7eqq8lhoBT0TbJyhf7EiaJq6IQSs3N2URmiXSp7o/H9+pt\niSHgXPgidMukpZZ3/aGUP/tZIlWV+EB9CDgZJoTSgiZFz9UXSvmTnyXShxPpssQQcDq6TGq/\n+gdVSvvGDq9kKK1abLh+fn1X//4e3m/D1QZEglQ6TAofp5k05UqpfuBDaVWRXjwfXu5LDAEn\nxLeQLmpS/GRCpVqnNfeRfn6+vq7XZ8nhNugRIkEGwiS3kZRl0qTlXUco5UJnA5RFwyQbm5Sg\nU+69uloq0SIEe6Kv1hut7oxzyWZl0pzl3cpLu6KGgP1RX2F3EEzyTQ7ylt1aJjWkaoRS9o8z\n5+/CPwn7SJCJr1V1YKywyZlkMkwaW97Z6J0XyD/YKpHafyGVRGMIOBiDL41XtS42aeGSQxRK\nLO1gNwz/T6yGSROOoIvlXe6PM/kvoqQhYIcML1X8RdGqJoXT7tk/zdS/hqKGgOPR2pqNTErR\nacbyLn+6HOyDQgklB2lSRhl84l3vNuj+5mAfLEivSclMXt7lT5aDfVAs3iQjTFrhQmn1o+Yc\n7INFiU2q11xZJk1d3mXDwT4oGL+hNMukKXXwXDjYB0UTTAp36NYzqe9J8ufJwT4om6ZJNpxR\nylBp8Ovt58qfJgf7oHCkSWYZkzYUiYN9sBbyOmm6SVkq5U+SzgYonk6TMq6S8k3KnyMiQflE\np5Fqk3yLQ/ohJUSCk9O1NbukSfkzRCTYA82t2cikRDKWd/kTRCTYBc2tWWdS52HX2Sblzw+R\nYCd0NjnkNbEmL+/yZ4dIsBcGTdK9UMqfHCLBbhg0qUo2KeVeXdkgEuwHfycHYZJdwqT8qSES\n7Ihek2y6SSnLu/yZIRLsCS2TRlTKnxgiwUS2uWGhNMk0V3dqB2fz54VIMI2tbv3p2xpeL3hv\nUlYZfPRWrNkgEkxiw5vovm5eHIp3r8/lhxIiwfZseTfqZhn8+TnV5V3+nBAJprHlXd2bJYfn\n5zRNyp8SIsFEtvztCComDSzv8meESLBHusrgiiblTwiRYJd0lcEnmdSpUv58EAn2yaIm5U8H\nkWCn9JmUt6HUvbzLnw0iwV5xW7PutpHupl0KoZQ/GUSC/dJlUna/UJdJ+VNBJNgxsl3ISJPy\nbtfVMil/JogEe0a2CymalD8RRIJdI9uF5pkkVcqfByLBvlnEpPxpIBLsnMgkM7XiEC/v8meB\nSLB3omZwb5IJIZVvUv4kEAl2jzzr502yk0z6HyLBiREbSv7xHJPyZ4BIcAQik6Znklve5U8A\nkeAQSJNs06QMXiblj49IcAz6TfJdrakm/Q+R4LyMmJSTSf/LHx2R4ChE9+nyJk0AkeDU+Ma7\n1wk/6/aX8m3KHxuR4DgYoc4sk/KHRiQ4EH5rdqZJ+SMjEhyK2CQz0aT8cREJjsWISWlG5Q+L\nSHAw5G88jy+bSCSAdPpNSpYpf1BEgsPRaZI7WiFl6hUrf0xEguPR+hVKtUk2NZbyh0QkOCC5\nJjU/lT8iIsERMWbAJBIJIJWXDT5w8kzKHw6R4KCEUPL3Yg1trCM25Y+GSHBUouKdN8mkmJQ/\nGCLBYek3aazkkD8WIsFxmWxS/lCIBAdGmmSESWMbSvkjIRIcGdnCalztbnxrNn8gRIJDY8wU\nk/LHQSQ4OEMmdUqESAAdNE3yJYcylnb/fV6rB9fbf0sNAaBBbJJpmNSlU/4YU1/l97cq8L7I\nEABKuK4Gf7PI+pP+dl3bNa3eqsu/n+ej3+9LdVtiCAAtQuOdtZFJfRtK2Ux9lV+qH//4p7os\nMQSAGiY03qWYlD/A1Fd5VfV9oDYEgB7hhJINJYdek/Kfn0SCcyDO+tUmVf1NDvlPP+Ma6fv3\n+YhrJNgFJgohU9UmieLdJk2r76Jq93ZfZAgAVTpNsl0m5T/3jH2k23Mf6XL9ZB8J9oEwqXqa\nZBombSFSSUMAJBGbVO8kWbehxHkkgDR6TTKRSflPjEhwKoRJttukDZtW2UeC3dA2yQiTtk2k\ntkiVRGMIACVaJsV1O8vSDiCFbpOsNCn/SREJzocx/Sb5E0t5IBKckLZJJjIp/xlnvsq/3qrq\n+r3oEAD6OIW8SVbqNOElO6/7u+4TGmy1QyQoEG+SiUxyZfBsZol0q253a39v1dcSQwAsiInr\nCzYyKf/pZol0qZ7dqvfqbYkhAJakx6SVr5GeIrktIjZkYYd0m7TFNdKHE4mDfbBD2ia5w3/5\nzzVdpOvn13f17+/h/cbBPtglvSblP9V0kXz7T1VdONgH+yRqWQ0m5T/R5Ff5z8/X1/X6LDnc\nBj1CJCgYcS8UZ5KZ8pKlswHOTdzk8PoMIgHk0moXotcOYALSpLoCnv8kiASnp2USSzuACTRN\nQiSAKXiTXrVwRAKYRntrNg9EAngQmZT/xxEJ4IkwiaUdwGREu1D+H0YkgBpvEokEMIOQSdkg\nEoDH3XU1/08iEkDgZRJLO4B5UP4GUIFEAtCARALQgEQC0IBEAlCARAJQAJEAFEAkAAUQCUAB\nRAJQAJEAFEAkAAUQCUABRAJQAJEAFEAk2C/Dv0B1VRAJdkv9a+uKAJFgr/hfAFkCiAR7BZFK\nGAL2T0EeIRLsmHI8QiQADRAJQAFEAlAAkQAUQCQABRAJQAFEAlAAkQAUQCQABRAJQAFEAlAA\nkQAUQCQABRAJQAFEAlAAkQAUQCQABRAJQAFEAlAAkQAUKFQkgJ0x4VWuL04RY02B+c3j1PND\npADzm8ep54dIAeY3j1PPD5ECzG8ep54fIgWY3zxOPT9ECjC/eZx6fogUYH7zOPX8ECnA/OZx\n6vkhUoD5zePU80OkAPObx6nnh0gB5jePU88PkQLMbx6nnl/pPzzALkAkAAUQCUABRAJQAJEA\nFEAkAAUQCUABRAJQAJEAFEAkAAUQCUABRAJQAJEAFEAkAAUQCUABRAJQYDWRbpfqcruvNVom\nX+6vochZfr35SZU4v/tHVX38vB6XOL8H/9X/wMvNby2R3p83+X9babRMftyvHyhylrfnpC6P\nf/4i53d5TuppUpHz++N+ef0DLzi/lUT6r7r82J9L9d86w+XxN6/XX0ORs/ypPu6PzPwodH63\nx8xu1dUWOr8H19c/8JLzW0mkW/X99/Zf9bnOcFl8Ve+1SEXO8vqa22OKRc7vUj2y8vk3WOT8\n7GNGr3/gJee3kkjX6tc+/sf1us5wWVQ3W4tU9CyroudXXWyx8/t1/0u55PxWEqmq5Luy+GlO\nr8RZ3qv3kud3q75ssfN7r35fU1pyfoj0oHyRvh6rklLn97d0uj3elzm/z+qfRaR1KF6k38tj\nOVLq/L6ul+d1R5Hze67kEGkdShfpfnl/vCt2ftZ+PNZ2Rc7v7bFxcBiRLiX+FQfqeRU7y/fX\n1kex83tcw13KnN/Hs1L3mtKS81u1avdbWj3HEVXtipvl79v77/NBofN7EqqKZc2v8iw7v5VE\n+nz+78L365q0PGqRypzld/VePypyfq99pN9Hv0CJ85MiLTk/OhselNzZ8Os9KnN+z86G+/Vx\njVTk/J4cprPBvj3/R+F9/Bs3wa2aS5zlR/hf1CLnV/faPSdV5Pwe1P/AC85vLZHuz77blQbL\nxolU4izF0qTI+T1bqt++no/KnJ/1/8ALzq+kAgvAbkEkAAUQCUABRAJQAJEAFEAkAAUQCUAB\nRAJQAJEAFEAkAAUQCUABRAJQAJEAFEAkAAUQCUABRAJQAJEAFEAkAAUQCUABRAJQAJEAFEAk\nAAUQCUABRAJQAJEAFEAkAAUQCUABRAJQAJEAFEAkAAUQCUABRAJQAJEAFEAkAAUQCUABRAJQ\nAJEAFECkXfJe/ff39r/qY+uJQA0i7ZLf6vL39nK5bz0RqEGkffJVfdrP6t/W0wAHIu2U9+qr\num49CfAg0k75rarqd+tJgAeR9sqtum09BQgg0k4hkcoCkXbK9e8a6X3rSYAHkfbJv7+F3Wf1\ntfU0wIFIu+R+ee4jsbgrBkTaJR91ZwOLu1JAJAAFEAlAAUQCUACRABRAJAAFEAlAAUQCUACR\nABRAJAAFEAlAAUQCUACRABRAJAAFEAlAAUQCUACRABRAJAAFEAlAAUQCUACRABRAJAAFEAlA\nAUQCUACRABRAJAAFEAlAAUQCUACRABRAJAAFEAlAAUQCUOD/KWlzF2tvKHkAAAAASUVORK5C\nYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(y ~ x, pch = 20)\n",
    "\n",
    "for (i in 1:500) {\n",
    " abline(posterior$alpha[i], posterior$beta[i], col = \"gray\", lty = 1)\n",
    "}\n",
    "\n",
    "abline(mean(posterior$alpha), mean(posterior$beta), col = 6, lw = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write(\"// Stan model for simple linear regression\n",
    "\n",
    "data {\n",
    " int < lower = 1 > N; // Sample size\n",
    " vector[N] x; // Predictor\n",
    " vector[N] y; // Outcome\n",
    "}\n",
    "\n",
    "parameters {\n",
    " real alpha; // Intercept\n",
    " real beta; // Slope (regression coefficients)\n",
    " real < lower = 0 > sigma; // Error SD\n",
    "}\n",
    "\n",
    "model {\n",
    " alpha ~ normal(10, 0.1);\n",
    " beta ~ normal(1, 0.1);\n",
    " y ~ normal(alpha + x * beta , sigma);\n",
    "}\n",
    "\n",
    "generated quantities {}\",\n",
    "\n",
    "\"stan_model2.stan\")\n",
    "\n",
    "stan_model2 <- \"scripts/users/imyerssmith/CC-Stan-Part-1/stan_model2.stan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot(posterior$alpha, type = \"l\")\n",
    "plot(posterior$beta, type = \"l\")\n",
    "plot(posterior$sigma, type = \"l\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
