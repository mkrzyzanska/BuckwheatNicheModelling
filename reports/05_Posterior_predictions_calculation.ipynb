{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posterior predictions calucations\n",
    "The following code calculates the posterior predictions for present buckwheat distribution, past buckwheat distribution and counterfactual plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load libraries\n",
    "library(rgdal) # for spatial data\n",
    "library(here) # for paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Source the utility functions:\n",
    "\n",
    "source(\"R/square.r\")\n",
    "source(\"R/calculatePredictions.r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the paths\n",
    "\n",
    "#Inputs\n",
    "path2model<-here(\"outputs\",\"models\",\"parabolic_iCAR.rds\")\n",
    "path2env_sd<-here(\"data\",\"Sd_Env_by_county.csv\")\n",
    "\n",
    "# Outputs\n",
    "path2predictions here(\"outputs\",\"05_01_Posterior_Predictions.csv\")\n",
    "path2past <- here(\"outputs\",\"05_02_Past_predictions_\")\n",
    "path2pred_summary <- here(\"outputs\",\"05_03_Predictions_summary.csv\")\n",
    "path2counterfactual <-here(\"outputs\",\"05_04_Counterfactual_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "\n",
    "env<-read.csv(path2env_sd)\n",
    "fit<-readRDS(path2model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extract posterior distribution for all parameters:\n",
    "posterior <- rstan::extract(fit) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Present distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Format new data to extract from the posterior\n",
    "\n",
    "# Define the size of the sample from the posterior:\n",
    "n=40000\n",
    "n_cnt=1000\n",
    "\n",
    "# Define the order of the variables:\n",
    "var_ordered<-c('BIO10','BIO17','BIO4','BIO9','npp')\n",
    "\n",
    "# Get relevant columns from the data frame:\n",
    "d<-env[ ,paste(var_ordered,\"sd\",sep=\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate predictions\n",
    "predictions<-calculatePredictions(fit, d, posterior,n,counterfactual=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save predictions:\n",
    "write.csv(predictions, path2predictions,col.names=FALSE, row.names=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Calculate predictions summary:\n",
    "means_pred<-apply(predictions,2, mean) # Calculate mean of each column (column==county)\n",
    "quantiles_pred<-apply(predictions,2, quantile,probs = c(0.05, 0.95)) # Calculate quantiles of each column (column==county)\n",
    "pred<-t(rbind(quantiles_pred, means_pred)) # Bind mean and quantiles, and transpose them, so that each county is a row now\n",
    "exp_pred<-exp(pred) # Exponentiate the predictions for all counties\n",
    "colnames(pred)<-paste(colnames(pred),\"_log\",sep=\"\") # Change original names of the columns with predictions, to indicate that they are in lograrithmic form\n",
    "pred<-cbind(pred,exp_pred) # Bind logarithmic and exponentiate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Past predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Calculate the predictions for the past:\n",
    "timeslices <-c(seq(1000,8000,by=1000),15000)\n",
    "# Loop over all time slices\n",
    "for (i in timeslices){\n",
    "    print(i)\n",
    "    data<-env[,grep(paste(\"_\",i,sep=\"\"),colnames(env))] # Get only the data for relevent time slice\n",
    "    data<-data[unlist(lapply(var_ordered,grep,colnames(data),value=TRUE))] # Change the order of the data, as required for predictions\n",
    "    predictions<-calculatePredictions(fit, data, posterior,n,counterfactual=FALSE) # Calculate predictions for the time slice\n",
    "    write.csv(predictions, paste(path2past,i,\".csv\",sep=\"\"),col.names=FALSE, row.names=FALSE) # Save past predictions\n",
    "    ### Also calculate the summary\n",
    "    means_pred<-apply(predictions,2, mean) # Calculate mean of each column (column==county)\n",
    "    quantiles_pred<-apply(predictions,2, quantile,probs = c(0.05, 0.95),na.rm=TRUE) # Calculate quantiles of each column (column==county)\n",
    "    fpred<-t(rbind(quantiles_pred, means_pred)) # Bind mean and quantiles, and transpose them, so that each county is a row now\n",
    "    exp_pred<-exp(fpred) # Exponentiate the predictions for all counties\n",
    "    colnames(exp_pred)<-paste(colnames(fpred),i,sep=\"_\") # Change original names of the columns with predictions, to indicate that they are in lograrithmic form\n",
    "    colnames(fpred)<-paste(colnames(fpred),i,\"log\",sep=\"_\")\n",
    "    fpred<-cbind(fpred,exp_pred) # Bind logarithmic and exponentiate predictions\n",
    "    pred<-cbind(pred,fpred)\n",
    "}\n",
    "\n",
    "### Write predictions to the file:\n",
    "write.csv(pred,path2pred_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counterfactual predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Calculate counterfactual predictions\n",
    "\n",
    "means<-colMeans(d) # Get mean valuse of all environmental variables\n",
    "means<-as.data.frame(rbind(means)) # Bind the mean values\n",
    "means<-means[rep(seq_len(nrow(means)), each = n_cnt), ] # Repeat each mean value n_cnt time\n",
    "range<-apply(d,2,range) # Get the range of all the data\n",
    "\n",
    "# Loop over all environmental variables\n",
    "for (i in 1:ncol(data)){\n",
    "    print(i)\n",
    "    new_data<-means # use means as new data\n",
    "    new_data[,i]<-seq(from = range[1,i], to = range[2,i],length.out=n_cnt) # substitute new values for one of the environmental variables\n",
    "    values<-new_data[,i] # Get the values for which predictions ar made\n",
    "    predictions<-calculatePredictions(fit, new_data, posterior,n,counterfactual=TRUE) # calculate predictions for new data\n",
    "    predictions<-t(predictions)\n",
    "    predictions<-cbind(values,predictions[,-1])\n",
    "    # Save counterfactual predictions\n",
    "    write.csv(predictions, gsub(\"predictions\", paste(\"predictions\",colnames(data)[i],sep=\"_\"),path2counterfactual),col.names=FALSE, row.names=FALSE)\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
